{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benny Cohen\n",
    "\n",
    "8/8/2020\n",
    "\n",
    "DAV 6150 M13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will be looking at a dataset about diamonds provided to us by the DAV 6150 course. We will try to classify the cut of the diamond. \n",
    "\n",
    "In order to do this we will examine the features of our dataset, prepare the data, then create different neural networks. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = 'cohenb51'\n",
    "path = 'Katz_School/develop/DAV6150/Project3_Data.csv'\n",
    "df = pd.read_csv(f'https://raw.githubusercontent.com/{username}/{path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53940, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['carat', 'cut', 'color', 'clarity', 'depth', 'table', 'price', 'x', 'y',\n",
       "       'z'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we have 10 columns and 53940 rows. This is a very long, but not very wide dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The description of the dataset can be found at https://ggplot2.tidyverse.org/reference/diamonds.html\n",
    "\n",
    "1. price - price in US dollars (326-18,823)\n",
    "\n",
    "2. carat - weight of the diamond (0.2--5.01)\n",
    "\n",
    "3. cut - quality of the cut (Fair, Good, Very Good, Premium, Ideal)\n",
    "\n",
    "4. color -  diamond colour, from D (best) to J (worst)\n",
    "\n",
    "5. clarity - a measurement of how clear the diamond is (I1 (worst), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (best))\n",
    "\n",
    "6. x - length in mm (0--10.74)\n",
    "\n",
    "7. y width in mm (0--58.9)\n",
    "\n",
    "8. z - depth in mm (0--31.8)\n",
    "\n",
    "9. depth - total depth percentage = z / mean(x, y) = 2 * z / (x + y) (43--79)\n",
    "\n",
    "10. table - width of top of diamond relative to widest point (43--95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of these variables we would think would be correlated with each other. For example, we would think that the higher the price, the larger the diamond would be and the better the cut. When it comes to the feature cut in particular though, the variable we are trying to predict, some of the variables like color logically won't relate to the cut."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a bit of domain knowledge, we can look at how diamond cuts are graded here. https://www.diamonds.pro/education/cuts/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key sentence I think we should focus in on is this line\n",
    "\n",
    "\"Many elements are involved in Cut quality including its proportions, facets, finishing details and ability to reflect light. The better these characterstics are as a whole, the higher the quality of the diamond, and in return, the higher the price.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see from this sentence how many of the features we have will effect the cut rating. We have several proportion features like x,y,z, and features for clarity and color which help define the diamonds ability to reflect light."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "carat      0\n",
       "cut        0\n",
       "color      0\n",
       "clarity    0\n",
       "depth      0\n",
       "table      0\n",
       "price      0\n",
       "x          0\n",
       "y          0\n",
       "z          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of our features have nulls..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat      cut color clarity  depth  table  price     x     y     z\n",
       "0   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n",
       "1   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "carat, depth, table,price,x,y,and z are all numeric. color, cut and clarity are categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x000001ABB9E212E8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001ABB9EB17F0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001ABB9EDCCC0>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x000001ABB9F0B278>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001ABB9F317F0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001ABB9F59D68>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x000001ABB9F8A320>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001ABBC1108D0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001ABBC110908>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist(figsize = (15,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carat and price are left skewed. depth, table, and z seem to have very large peaks. \n",
    "\n",
    "It makes sense that Carat and price are let skewed. Price is naturally tied to carat as when people buy diamonds they are paying per carat. Most diamonds have low low weights and a few have high and sell for more. That's why both graphs are rightly skewed.\n",
    "\n",
    "The large peaks for the dimensions indicates that there isn't that much variance but it seems slightly odd that there are outliers stretching the graph out very far. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.797940</td>\n",
       "      <td>61.749405</td>\n",
       "      <td>57.457184</td>\n",
       "      <td>3932.799722</td>\n",
       "      <td>5.731157</td>\n",
       "      <td>5.734526</td>\n",
       "      <td>3.538734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.474011</td>\n",
       "      <td>1.432621</td>\n",
       "      <td>2.234491</td>\n",
       "      <td>3989.439738</td>\n",
       "      <td>1.121761</td>\n",
       "      <td>1.142135</td>\n",
       "      <td>0.705699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>326.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>950.000000</td>\n",
       "      <td>4.710000</td>\n",
       "      <td>4.720000</td>\n",
       "      <td>2.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>61.800000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>2401.000000</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>5.710000</td>\n",
       "      <td>3.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.040000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>5324.250000</td>\n",
       "      <td>6.540000</td>\n",
       "      <td>6.540000</td>\n",
       "      <td>4.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.010000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>18823.000000</td>\n",
       "      <td>10.740000</td>\n",
       "      <td>58.900000</td>\n",
       "      <td>31.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              carat         depth         table         price             x  \\\n",
       "count  53940.000000  53940.000000  53940.000000  53940.000000  53940.000000   \n",
       "mean       0.797940     61.749405     57.457184   3932.799722      5.731157   \n",
       "std        0.474011      1.432621      2.234491   3989.439738      1.121761   \n",
       "min        0.200000     43.000000     43.000000    326.000000      0.000000   \n",
       "25%        0.400000     61.000000     56.000000    950.000000      4.710000   \n",
       "50%        0.700000     61.800000     57.000000   2401.000000      5.700000   \n",
       "75%        1.040000     62.500000     59.000000   5324.250000      6.540000   \n",
       "max        5.010000     79.000000     95.000000  18823.000000     10.740000   \n",
       "\n",
       "                  y             z  \n",
       "count  53940.000000  53940.000000  \n",
       "mean       5.734526      3.538734  \n",
       "std        1.142135      0.705699  \n",
       "min        0.000000      0.000000  \n",
       "25%        4.720000      2.910000  \n",
       "50%        5.710000      3.530000  \n",
       "75%        6.540000      4.040000  \n",
       "max       58.900000     31.800000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another note is that the z and y seem to have values at 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.x == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.y == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.z == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat      cut color clarity  depth  table  price     x     y     z\n",
       "0   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n",
       "1   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n",
       "2   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n",
       "3   0.29  Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n",
       "4   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 7 values with y of 0 and 20 values of z = 0. Let's see what these rows are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11963</th>\n",
       "      <td>1.00</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>H</td>\n",
       "      <td>VS2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>53.0</td>\n",
       "      <td>5139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15951</th>\n",
       "      <td>1.14</td>\n",
       "      <td>Fair</td>\n",
       "      <td>G</td>\n",
       "      <td>VS1</td>\n",
       "      <td>57.5</td>\n",
       "      <td>67.0</td>\n",
       "      <td>6381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24520</th>\n",
       "      <td>1.56</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>G</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>12800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26243</th>\n",
       "      <td>1.20</td>\n",
       "      <td>Premium</td>\n",
       "      <td>D</td>\n",
       "      <td>VVS1</td>\n",
       "      <td>62.1</td>\n",
       "      <td>59.0</td>\n",
       "      <td>15686</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27429</th>\n",
       "      <td>2.25</td>\n",
       "      <td>Premium</td>\n",
       "      <td>H</td>\n",
       "      <td>SI2</td>\n",
       "      <td>62.8</td>\n",
       "      <td>59.0</td>\n",
       "      <td>18034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49556</th>\n",
       "      <td>0.71</td>\n",
       "      <td>Good</td>\n",
       "      <td>F</td>\n",
       "      <td>SI2</td>\n",
       "      <td>64.1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49557</th>\n",
       "      <td>0.71</td>\n",
       "      <td>Good</td>\n",
       "      <td>F</td>\n",
       "      <td>SI2</td>\n",
       "      <td>64.1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       carat        cut color clarity  depth  table  price    x    y    z\n",
       "11963   1.00  Very Good     H     VS2   63.3   53.0   5139  0.0  0.0  0.0\n",
       "15951   1.14       Fair     G     VS1   57.5   67.0   6381  0.0  0.0  0.0\n",
       "24520   1.56      Ideal     G     VS2   62.2   54.0  12800  0.0  0.0  0.0\n",
       "26243   1.20    Premium     D    VVS1   62.1   59.0  15686  0.0  0.0  0.0\n",
       "27429   2.25    Premium     H     SI2   62.8   59.0  18034  0.0  0.0  0.0\n",
       "49556   0.71       Good     F     SI2   64.1   60.0   2130  0.0  0.0  0.0\n",
       "49557   0.71       Good     F     SI2   64.1   60.0   2130  0.0  0.0  0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.y == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>1.00</td>\n",
       "      <td>Premium</td>\n",
       "      <td>G</td>\n",
       "      <td>SI2</td>\n",
       "      <td>59.1</td>\n",
       "      <td>59.0</td>\n",
       "      <td>3142</td>\n",
       "      <td>6.55</td>\n",
       "      <td>6.48</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2314</th>\n",
       "      <td>1.01</td>\n",
       "      <td>Premium</td>\n",
       "      <td>H</td>\n",
       "      <td>I1</td>\n",
       "      <td>58.1</td>\n",
       "      <td>59.0</td>\n",
       "      <td>3167</td>\n",
       "      <td>6.66</td>\n",
       "      <td>6.60</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4791</th>\n",
       "      <td>1.10</td>\n",
       "      <td>Premium</td>\n",
       "      <td>G</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>3696</td>\n",
       "      <td>6.50</td>\n",
       "      <td>6.47</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5471</th>\n",
       "      <td>1.01</td>\n",
       "      <td>Premium</td>\n",
       "      <td>F</td>\n",
       "      <td>SI2</td>\n",
       "      <td>59.2</td>\n",
       "      <td>58.0</td>\n",
       "      <td>3837</td>\n",
       "      <td>6.50</td>\n",
       "      <td>6.47</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10167</th>\n",
       "      <td>1.50</td>\n",
       "      <td>Good</td>\n",
       "      <td>G</td>\n",
       "      <td>I1</td>\n",
       "      <td>64.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>4731</td>\n",
       "      <td>7.15</td>\n",
       "      <td>7.04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11182</th>\n",
       "      <td>1.07</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>F</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.6</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4954</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11963</th>\n",
       "      <td>1.00</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>H</td>\n",
       "      <td>VS2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>53.0</td>\n",
       "      <td>5139</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13601</th>\n",
       "      <td>1.15</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>G</td>\n",
       "      <td>VS2</td>\n",
       "      <td>59.2</td>\n",
       "      <td>56.0</td>\n",
       "      <td>5564</td>\n",
       "      <td>6.88</td>\n",
       "      <td>6.83</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15951</th>\n",
       "      <td>1.14</td>\n",
       "      <td>Fair</td>\n",
       "      <td>G</td>\n",
       "      <td>VS1</td>\n",
       "      <td>57.5</td>\n",
       "      <td>67.0</td>\n",
       "      <td>6381</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24394</th>\n",
       "      <td>2.18</td>\n",
       "      <td>Premium</td>\n",
       "      <td>H</td>\n",
       "      <td>SI2</td>\n",
       "      <td>59.4</td>\n",
       "      <td>61.0</td>\n",
       "      <td>12631</td>\n",
       "      <td>8.49</td>\n",
       "      <td>8.45</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24520</th>\n",
       "      <td>1.56</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>G</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>12800</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26123</th>\n",
       "      <td>2.25</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>SI1</td>\n",
       "      <td>61.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>15397</td>\n",
       "      <td>8.52</td>\n",
       "      <td>8.42</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26243</th>\n",
       "      <td>1.20</td>\n",
       "      <td>Premium</td>\n",
       "      <td>D</td>\n",
       "      <td>VVS1</td>\n",
       "      <td>62.1</td>\n",
       "      <td>59.0</td>\n",
       "      <td>15686</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27112</th>\n",
       "      <td>2.20</td>\n",
       "      <td>Premium</td>\n",
       "      <td>H</td>\n",
       "      <td>SI1</td>\n",
       "      <td>61.2</td>\n",
       "      <td>59.0</td>\n",
       "      <td>17265</td>\n",
       "      <td>8.42</td>\n",
       "      <td>8.37</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27429</th>\n",
       "      <td>2.25</td>\n",
       "      <td>Premium</td>\n",
       "      <td>H</td>\n",
       "      <td>SI2</td>\n",
       "      <td>62.8</td>\n",
       "      <td>59.0</td>\n",
       "      <td>18034</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27503</th>\n",
       "      <td>2.02</td>\n",
       "      <td>Premium</td>\n",
       "      <td>H</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.7</td>\n",
       "      <td>53.0</td>\n",
       "      <td>18207</td>\n",
       "      <td>8.02</td>\n",
       "      <td>7.95</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27739</th>\n",
       "      <td>2.80</td>\n",
       "      <td>Good</td>\n",
       "      <td>G</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.8</td>\n",
       "      <td>58.0</td>\n",
       "      <td>18788</td>\n",
       "      <td>8.90</td>\n",
       "      <td>8.85</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49556</th>\n",
       "      <td>0.71</td>\n",
       "      <td>Good</td>\n",
       "      <td>F</td>\n",
       "      <td>SI2</td>\n",
       "      <td>64.1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2130</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49557</th>\n",
       "      <td>0.71</td>\n",
       "      <td>Good</td>\n",
       "      <td>F</td>\n",
       "      <td>SI2</td>\n",
       "      <td>64.1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2130</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51506</th>\n",
       "      <td>1.12</td>\n",
       "      <td>Premium</td>\n",
       "      <td>G</td>\n",
       "      <td>I1</td>\n",
       "      <td>60.4</td>\n",
       "      <td>59.0</td>\n",
       "      <td>2383</td>\n",
       "      <td>6.71</td>\n",
       "      <td>6.67</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       carat        cut color clarity  depth  table  price     x     y    z\n",
       "2207    1.00    Premium     G     SI2   59.1   59.0   3142  6.55  6.48  0.0\n",
       "2314    1.01    Premium     H      I1   58.1   59.0   3167  6.66  6.60  0.0\n",
       "4791    1.10    Premium     G     SI2   63.0   59.0   3696  6.50  6.47  0.0\n",
       "5471    1.01    Premium     F     SI2   59.2   58.0   3837  6.50  6.47  0.0\n",
       "10167   1.50       Good     G      I1   64.0   61.0   4731  7.15  7.04  0.0\n",
       "11182   1.07      Ideal     F     SI2   61.6   56.0   4954  0.00  6.62  0.0\n",
       "11963   1.00  Very Good     H     VS2   63.3   53.0   5139  0.00  0.00  0.0\n",
       "13601   1.15      Ideal     G     VS2   59.2   56.0   5564  6.88  6.83  0.0\n",
       "15951   1.14       Fair     G     VS1   57.5   67.0   6381  0.00  0.00  0.0\n",
       "24394   2.18    Premium     H     SI2   59.4   61.0  12631  8.49  8.45  0.0\n",
       "24520   1.56      Ideal     G     VS2   62.2   54.0  12800  0.00  0.00  0.0\n",
       "26123   2.25    Premium     I     SI1   61.3   58.0  15397  8.52  8.42  0.0\n",
       "26243   1.20    Premium     D    VVS1   62.1   59.0  15686  0.00  0.00  0.0\n",
       "27112   2.20    Premium     H     SI1   61.2   59.0  17265  8.42  8.37  0.0\n",
       "27429   2.25    Premium     H     SI2   62.8   59.0  18034  0.00  0.00  0.0\n",
       "27503   2.02    Premium     H     VS2   62.7   53.0  18207  8.02  7.95  0.0\n",
       "27739   2.80       Good     G     SI2   63.8   58.0  18788  8.90  8.85  0.0\n",
       "49556   0.71       Good     F     SI2   64.1   60.0   2130  0.00  0.00  0.0\n",
       "49557   0.71       Good     F     SI2   64.1   60.0   2130  0.00  0.00  0.0\n",
       "51506   1.12    Premium     G      I1   60.4   59.0   2383  6.71  6.67  0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.z == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11182</th>\n",
       "      <td>1.07</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>F</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.6</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4954</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11963</th>\n",
       "      <td>1.00</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>H</td>\n",
       "      <td>VS2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>53.0</td>\n",
       "      <td>5139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15951</th>\n",
       "      <td>1.14</td>\n",
       "      <td>Fair</td>\n",
       "      <td>G</td>\n",
       "      <td>VS1</td>\n",
       "      <td>57.5</td>\n",
       "      <td>67.0</td>\n",
       "      <td>6381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24520</th>\n",
       "      <td>1.56</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>G</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>12800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26243</th>\n",
       "      <td>1.20</td>\n",
       "      <td>Premium</td>\n",
       "      <td>D</td>\n",
       "      <td>VVS1</td>\n",
       "      <td>62.1</td>\n",
       "      <td>59.0</td>\n",
       "      <td>15686</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27429</th>\n",
       "      <td>2.25</td>\n",
       "      <td>Premium</td>\n",
       "      <td>H</td>\n",
       "      <td>SI2</td>\n",
       "      <td>62.8</td>\n",
       "      <td>59.0</td>\n",
       "      <td>18034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49556</th>\n",
       "      <td>0.71</td>\n",
       "      <td>Good</td>\n",
       "      <td>F</td>\n",
       "      <td>SI2</td>\n",
       "      <td>64.1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49557</th>\n",
       "      <td>0.71</td>\n",
       "      <td>Good</td>\n",
       "      <td>F</td>\n",
       "      <td>SI2</td>\n",
       "      <td>64.1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       carat        cut color clarity  depth  table  price    x     y    z\n",
       "11182   1.07      Ideal     F     SI2   61.6   56.0   4954  0.0  6.62  0.0\n",
       "11963   1.00  Very Good     H     VS2   63.3   53.0   5139  0.0  0.00  0.0\n",
       "15951   1.14       Fair     G     VS1   57.5   67.0   6381  0.0  0.00  0.0\n",
       "24520   1.56      Ideal     G     VS2   62.2   54.0  12800  0.0  0.00  0.0\n",
       "26243   1.20    Premium     D    VVS1   62.1   59.0  15686  0.0  0.00  0.0\n",
       "27429   2.25    Premium     H     SI2   62.8   59.0  18034  0.0  0.00  0.0\n",
       "49556   0.71       Good     F     SI2   64.1   60.0   2130  0.0  0.00  0.0\n",
       "49557   0.71       Good     F     SI2   64.1   60.0   2130  0.0  0.00  0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.x == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the rows with 0 values for x and y also have 0 values for 0. This seems like a data collection problem. In theory if we were short on data we could impute these values but this is such a low proportion of our dataset we could drop them. It probably wouldn't make that much of a difference even if we included them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.z > 7).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 values with a depth > 7. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.y > 15).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise 2 values have a very large y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24067</th>\n",
       "      <td>2.00</td>\n",
       "      <td>Premium</td>\n",
       "      <td>H</td>\n",
       "      <td>SI2</td>\n",
       "      <td>58.9</td>\n",
       "      <td>57.0</td>\n",
       "      <td>12210</td>\n",
       "      <td>8.09</td>\n",
       "      <td>58.90</td>\n",
       "      <td>8.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48410</th>\n",
       "      <td>0.51</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>61.8</td>\n",
       "      <td>54.7</td>\n",
       "      <td>1970</td>\n",
       "      <td>5.12</td>\n",
       "      <td>5.15</td>\n",
       "      <td>31.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       carat        cut color clarity  depth  table  price     x      y      z\n",
       "24067   2.00    Premium     H     SI2   58.9   57.0  12210  8.09  58.90   8.06\n",
       "48410   0.51  Very Good     E     VS1   61.8   54.7   1970  5.12   5.15  31.80"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.z>7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24067</th>\n",
       "      <td>2.00</td>\n",
       "      <td>Premium</td>\n",
       "      <td>H</td>\n",
       "      <td>SI2</td>\n",
       "      <td>58.9</td>\n",
       "      <td>57.0</td>\n",
       "      <td>12210</td>\n",
       "      <td>8.09</td>\n",
       "      <td>58.9</td>\n",
       "      <td>8.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49189</th>\n",
       "      <td>0.51</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>61.8</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2075</td>\n",
       "      <td>5.15</td>\n",
       "      <td>31.8</td>\n",
       "      <td>5.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       carat      cut color clarity  depth  table  price     x     y     z\n",
       "24067   2.00  Premium     H     SI2   58.9   57.0  12210  8.09  58.9  8.06\n",
       "49189   0.51    Ideal     E     VS1   61.8   55.0   2075  5.15  31.8  5.12"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.y>15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing strikes out about these rows to me other than that there y/z seems to be off by more than a factor of 10. I don't think this will really effect our model if we include them but we might as well drop them since its only 3 records. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1abbe74a3c8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWwAAAD8CAYAAABTjp5OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAHQ1JREFUeJzt3XmcXGWd7/HPtztkQQIEcGFAJGJE4apRm0W9LqBgdATcUKIIuNy4RRGvo3B1AFFmGL3gVcCRFhEUFAH1TryATAyICjImsi8iMSDEoBEiiiyBJL/7x3lajkVV96mqU6k6p79vX8+rz35+1cFfPf2c5zyPIgIzMxt8Q/0OwMzMinHCNjOrCCdsM7OKcMI2M6sIJ2wzs4pwwjYzqwgnbDOzFiSdIWm1pBtb7JekL0laLul6SS/I7TtU0m2pHFpGPE7YZmatnQnMG2f/a4A5qSwA/h1A0lbAMcAewO7AMZJmdRuME7aZWQsR8RNgzTiHHAB8IzJXAVtK2hZ4NbA4ItZExJ+AxYyf+AuZ0u0FJjJjh/kD+SrlpcsO7ncITS353bR+h9DUyW+7pN8htPTgw/f0O4SmpgzP6HcIlfOn5V9Wt9doJ+c8fNe57yWrGY8ZjYjRNm63HXBXbn1l2tZqe1d6nrDNzAZVSs7tJOhGzb5gYpztXXGTiJnVijRUuJRgJfDU3Pr2wKpxtnfFCdvMamVIUwqXEiwCDkm9RfYE/hwRdwOXAPtKmpUeNu6btnXFTSJmVisl1ZzTtfRt4BXANpJWkvX82AQgIr4CXAS8FlgOPAi8M+1bI+kzwNJ0qeMiYryHl4U4YZtZrUhdP7f8m4iYP8H+AD7YYt8ZwBmlBYMTtpnVTn1bep2wzaxWymwSGTRO2GZWK07YZmYVUVLvj4FU309mZpOSa9hmZhXhhG1mVhFq+lZ4PThhm1mt1LmGXeiTSTq8yDYzs34bGppSuFRN0a+iZrMlHFZiHGZmJRlqo1TLuF8xkuYDbwNmS1qU2zUTuHec8xaQxpidMmuEKZs9o4RQzcwmVucmkYn+JrgSuBvYBjgxt/1+4PpWJ+XHmB3UCQzMrJ4mbcKOiN8CvwVetHHCMTPrjirY1FFU0YeOe0paKumvkh6RtF7SX3odnJlZuzbyBAYbVdHHpKcABwHnAyPAIYAbps1s4AwNDfc7hJ4p3K8lIpZLGo6I9cDXJV3Zw7jMzDpS5yaRogn7QUlTgWslfY7sQeQTeheWmVlnqtjUUVTRT/aOdOxC4AGyySXf1KugzMw6NanbsCUNA8dHxMHAw8Cnex6VmVmHJnWTSESsl/RESVMj4pGNEZSZWadUwVfOiyr6ye4ArkhvOz4wtjEiTupFUGZmnSpzEt5BUzRhr0pliOy1dDOzgTSpm0QAIsLt1mZWCVV8mFhUoYQt6YnAx4Fdgelj2yNi7x7FZWbWmRo3iRT9KjoH+BUwm6yXyB3A0h7FZGbWufqOrlq4DXvriPiapMMj4nLgckmXFznx0mUHdx5dD+09cna/Q2jqoTsHs/Vpvyte3u8QWpoyoBWqQa3o3bimvr0oABiqYCYuqOi/3KPp592S/pHsAeT2vQnJzKwL9c3XhRP2ZyVtAfxP4GRgc+AjPYvKzKxDMah/2pSg6HfRgYAi4saI2AvYB3hD78IyM+uQ2igVU7SG/dyIuG9sJSLWSHp+j2IyM+vcUAUzcUFFa9hDkmaNrUjaijaGZjUz22ik4qViiibdE4ErJV0ABPAW4PieRWVm1qnh6iXiooq+6fgNScuAvclaft4YETf3NDIzs05UsOZcVDszztwMOEmb2WArMV9Lmgd8ERgGTo+IExr2fwHYK61uCjwpIrZM+9YDN6R9d0bE/t3G43ZoM6uXkh46prkATiXrFbcSWCppUb51ISKOyB3/ISDfGeOhiJhbSjBJjbuYm9mkVF63vt2B5RGxIs0FcC5wwDjHzwe+3U3oE3HCNrNaieGhwkXSAknLcmVB7lLbAXfl1lembY8j6WlkYy1dmts8PV3zKkmvL+OzuUnEzOqljRaRiBgFRtu4UrQ49iDggohYn9u2Q0SskvR04FJJN0TEb4pH93iuYZtZvZTXD3sl2YTjY7YnG0epmYNoaA6JiFXp5wrgx/x9+3ZHnLDNrF6GVLyMbykwR9JsSVPJkvKixoMk7QzMAn6e2zZL0rS0vA3wEkroZVe4SSQ9MX1y/pyIuLPbAMzMSlVSt76IWCdpIXAJWbe+MyLiJknHAcsiYix5zwfOjYh8c8mzgdMkbSCrGJ9QxrsrRWec+RBwDPAHYMPY5wGe2+L4BcACgI9/fiGvP2Ret3GamRVT4oszEXERcFHDtqMb1o9tct6VwHNKCyQpWsM+HNg5Iu4tcnC+If/nqy9s1UhvZla+yf5qOlnXlj/3MhAzs1JM1lfTJX00La4AfizpQmDt2P6IOKmHsZmZta+++XrCGvbM9PPOVKamAq37I5qZ9U3UeDzscRN2RHwaQNKBEXF+fp+kA3sZmJlZR2rcJFK0H/ZRBbeZmfXXZJ0iTNJrgNcC20n6Um7X5sC6XgZmZtaR4fq+DzhRG/YqYBmwP/DL3Pb7gSOanmFm1k8VrDkXNVEb9nXAdZK+RfZreBbZw8Zb03CDZmaDZbI+dMzZBzgN+A1Z4p4t6b0RcXHPIjMz64QTNicBe0XEcgBJOwEXAk7YZjZQor75unDCXj2WrJMVwOoexGNm1p1J/NBxzE2SLgLOI2vDPpBsfrM3AkTE93oUn5lZe9wkwnSykfpentb/CGwF7EeWwJ2wzWww1LeCXSxhR8Q7O73Bkt9N6/TUnnrozk/3O4SmZuxwTL9DaOqUxYf1O4SW7vjrcL9DaGragCaOmVM3THxQlU32Nx0lPVPSEkk3pvXnSvpUb0MzM+tAeTPODJyidYCvkr2K/ihARFxPNl2OmdlACalwqZqibdibRsQv9Pcf0K+mm9ngmVK9RFxU0YR9T+p7HQCS3gzc3bOozMw6VcGac1FFE/YHyab8epak3wG3A2/vWVRmZp2qYNt0UUVnnIFsIsrLyNq9HwDeRPYGpJnZ4Khvvi4848zOwG7Af5D9Ot4B/KSHcZmZdcQzzkj/CbwgIu5P68cC549zqplZf0zWhJ2zA5AfTvURYMfSozEz69awE/Y3gV9I+j5ZT5E3AGf1LCozs05N9l4iEXG8pIuBl6ZN74yIa3oXlplZh9wkAhFxNXB1D2MxM+ueE7aZWTVU8ZXzopywzaxeavzQccLBnyRtKumfJX01rc+R9Lreh2Zm1oFJPlrf14G1wIvS+krgs+OdIGmBpGWSli397oVdhmhm1oZJnrB3iojP8djQqg8xwcufETEaESMRMbLbm/6xhDDNzApSG6ViirRhPyJpBo+N1LcTWY3bzGzg1PnV9CI17GOAHwJPlXQOsAT4eE+jMjPrlFS8THgpzZN0q6Tlko5ssv8wSX+UdG0q78ntO1TSbakcWsZHm7CGHRGLJV0N7En2R8ThEXFPGTc3MytdSb1EJA0DpwL7kD27WyppUUTc3HDodyJiYcO5W5FVdkfIWid+mc79UzcxtUzYkl7QsGlswoIdJO2QXqQxMxsoQ+VNfrw7sDwiVgBIOhc4AGhM2M28GlgcEWvSuYuBecC3uwlovBr2iePsC2Dvbm5sZtYL7bw3I2kBsCC3aTQiRtPydsBduX0rgT2aXOZNkl4G/Bo4IiLuanHudsUja65lwo6Ivbq9uJnZxtZOwk7JebTF7mZXiob1HwDfjoi1kt5HNije3gXPbVuRF2emS/qopO9J+q6kj0ia3u2Nzcx6QVLhMoGVwFNz69sDq/IHRMS9ETHWa+6rwAuLntuJIq093wB2BU4GTgF2IRtu1cxs4AwNFS8TWArMkTRb0lTgIGBR/gBJ2+ZW9wduScuXAPtKmiVpFrBv2taVIv2wd46I5+XWL5N0Xbc3NjPrBZX00DEi1klaSJZoh4EzIuImSccByyJiEfBhSfsD64A1wGHp3DWSPkOW9AGOG3sA2Y0iCfsaSXtGxFUAkvYAruj2xmZmvVDmYH0RcRHZBOT5bUfnlo8Cjmpx7hnAGeVFM363vhvIGsk3AQ6RdGdafxrFurWYmW10NX7RcdwatkfkM7PKqfFw2ON26/ttfl3SkwD3DjGzgTYpE/aY1KB+IvAPwGqyJpFbyHqOTOjkt3X9YLQn9rvi5f0OoalTFh/W7xCaWrjPmf0OoaVttnx2v0NoasrwYNZvVKhzWH8cfs2+XV9jaDJPYAB8hmwckV9HxGzglfiho5kNqBLHfho4RRL2oxFxLzAkaSgiLgPm9jguM7OO1DlhF+nWd5+kzYCfAOdIWk2azMDMbNBUMREXVSRhXwc8CBwBvB3YAtisl0GZmXVqsnbrG7NXRGwANpANbIKk63salZlZhyZlDVvS+4EPADs1JOiZ+KGjmQ2oOvcSGa+G/S3gYuBfgfzUOPeX8U68mVkvTMoadkT8GfgzMH/jhWNm1p1JmbDNzKrICdvMrCImey8RM7PKGBrudwS944RtZrXiJhEzs4ooMFdjZTlhm1mt1DhfFx9nUdLTJL0qLc+QNLN3YZmZdabOgz8VStiS/gdwAXBa2rQ98H/HOX6BpGWSlj10n+frNbONZ9InbOCDwEuAvwBExG3Ak1odHBGjETESESMztnxeq8PMzEo3Zah4qZqibdhrI+KRscZ8SVPIJuQ1MxsoQ6pvaiqasC+X9L+AGZL2IRsU6ge9C8vMrDN1fnGm6B8FRwJ/BG4A3gtcBHyqV0GZmXVqqI1SNUVr2DOAMyLiqwCShtO2B3sVmJlZJ+rcJFL0S2YJWYIeMwP4UfnhmJl1Z0jFS9UUrWFPj4i/jq1ExF8lbdqjmMzMOjalgom4qKI17AckvWBsRdILgYd6E5KZWeekKFyqpmgN+yPA+ZJWpfVtgbf2JiQzs85VsamjqEIJOyKWSnoWsDMg4FcR8WhPIzMz60AVe38UNW7ClrR3RFwq6Y0Nu+ZIIiK+18PYzMzaVudeIhPVsF8OXArs12RfAE7YZjZQ6vzQcdyEHRHHSBoCLo6I8zZSTGZmHatzG/aEzT0RsQFYuBFiMTPr2pCicJmIpHmSbpW0XNKRTfZ/VNLNkq6XtETS03L71ku6NpVFZXy2or1EFkv6GPAd4IGxjRGxZqITH3z4ng5D661B/bPpjr8O5oR022z57H6H0NI9993S7xCamjI8vd8hNFXnGVmgvBp2eqP7VGAfYCWwVNKiiLg5d9g1wEhEPCjp/cDneKwH3UMRMbecaDJFE/a7yNqsP9Cw/ellBmNm1q0Se4nsDiyPiBUAks4FDgD+lrAj4rLc8VcBB5d3+8cr+tl2IfumuQ64FjgZ2LVXQZmZdaqdJpH8ZCupLMhdajvgrtz6yrStlXcDF+fWp6drXiXp9WV8tqI17LPIJi/4Ulqfn7a9pYwgzMzK0s7EBBExCoy22N2scaVpw7ekg4ERsp51Y3aIiFWSng5cKumGiPhN8eger2jC3jki8lPHXCbJc3+Z2cApsUlkJfDU3Pr2wKrGg9Jct58EXh4Ra8e2R8Sq9HOFpB8Dzwe6SthFP9s1kvbMBbgHcEU3NzYz64USe4ksJXtJcLakqcBBwN/19pD0fLK5bvePiNW57bMkTUvL25BNsZh/WNmRojXsPYBDJN2Z1ncAbpF0AxAR8dxuAzEzK0NZvUQiYp2khcAlwDDZnAA3SToOWBYRi4DPA5uRjbUEcGdE7A88GzhN0gayivEJDb1LOlI0Yc/r9kZmZhtDmWOJRMRFZDNs5bcdnVt+VYvzrgSeU2IoQPHBn35b9o3NzHqhzm86Fq1hm5lVwvDQ5B38ycysUibt8KpmZlUzmYdXNTOrFLdhm5lVRJ0T9oTNPZJ2abLtFT2JxsysS5soCpeqKdI+f56kTygzQ9LJwL/2OjAzs04MqXipmiIJew+y9+mvJHtVcxXZa5Yt5UfAevT+W7uP0sysoMmesB8FHgJmANOB29MsNC1FxGhEjETEyCYzdy4hTDOzYoZVvFRNkYS9lCxh7wb8d2C+pAt6GpWZWYfqXMMu0kvk3RGxLC3/HjhA0jt6GJOZWccmdT/sXLLOb/tmb8IxM+vOJhWsORflfthmVitVbOooygnbzGplUjeJmJlVSRV7fxTlhG1mteImETOzimhn1vSqccI2s1oZdhu2mVk11LiC7YRtZvXiNmwzs4pwwjYzqwi3YXdzg+EZvb5FRzSg38LTBrQB7r1nvZivvevqfofR1JTh6f0Ooal16x/udwhNTZ86q98h9JR7idikN6jJ2qyRm0TMzCrCbzqamVWExxIxM6uIGjdhO2GbWb24DdvMrCI2GXKTiJlZJbiGbWZWEU7YZmYVUeeHjnX+bGY2CUnFy8TX0jxJt0paLunIJvunSfpO2v9fknbM7Tsqbb9V0qvL+GxO2GZWK0MqXsYjaRg4FXgNsAswX9IuDYe9G/hTRDwD+ALwb+ncXYCDgF2BecCX0/W6+2zdXsDMbJAMtVEmsDuwPCJWRMQjwLnAAQ3HHACclZYvAF4pSWn7uRGxNiJuB5an63XFCdvMakWKNooWSFqWKwtyl9oOuCu3vjJto9kxEbEO+DOwdcFz2zbhQ0dJC4FzIuJP3d7MzKzX2ukkEhGjwGgbl2rs5N3qmCLntq1IDfspwFJJ56UG+Bp3mjGzqivxoeNK4Km59e2BVa2OkTQF2AJYU/Dctk2YsCPiU8Ac4GvAYcBtkv5F0k6tzsn/mbH2Lzd3G6OZWWFqo0xgKTBH0mxJU8keIi5qOGYRcGhafjNwaURE2n5Q6kUymyyH/qKrD0bBNuwUwO9TWQfMAi6Q9LkWx49GxEhEjEzbvPGhqplZ7wyreBlPapNeCFwC3AKcFxE3STpO0v7psK8BW0taDnwUODKdexNwHnAz8EPggxGxvtvPVqQN+8Nk3yD3AKcD/xQRj0oaAm4DPt5tEGZmZSmz0TYiLgIuath2dG75YeDAFuceDxxfXjTF3nTcBnhjRPy2IZgNkl5XZjBmZt2q80O2CRN2/tukyb5byg3HzKw7kzphm5lViQd/MjOriBrnaydsM6sXz+loZlYRdX61zwnbzGqlzgMkOWGbWa24hm1mVhE1ztdO2GZWL+7WZ2ZWEU7YZmYVUeN8PXkT9o1rBvOjz5y6od8hNPWRs+fyxYOv73cYTQ3qEO3Tp87qdwhNPfxIvecikfth22Q3qMnarNFgfn2XwwnbzGplQP/gKoUTtpnVynC/A+ghJ2wzqxXXsM3MKqO+GdsJ28xqRU7YZmbVkE03W09O2GZWM65hm5lVgmo8wKoTtpnViptEzMwqw00iZmaV4F4iZmYVUeeEXaixR9ISSa9t2Dbam5DMzDonDRcuVVO0dX428AlJx+S2jfQgHjOzLqmNUi1FE/Z9wCuBJ0v6gaQtxjtY0gJJyyQtW/uXm7sO0sysKLXxv6opmrAVEesi4gPAd4GfAU9qdXBEjEbESESMTNt8lzLiNDMraKiNUi1FHzp+ZWwhIs6UdAPwwd6EZGbWuSrWnIsqlLAj4rSG9V8C7+pJRGZmXRjUKePK4G59ZlYrqvEUBtVrxDEzG9fG6SUiaStJiyXdln4+btZlSXMl/VzSTZKul/TW3L4zJd0u6dpU5k50TydsM6sVSYVLl44ElkTEHGBJWm/0IHBIROwKzAP+j6Qtc/v/KSLmpnLtRDd0wjazmtlo/bAPAM5Ky2cBr288ICJ+HRG3peVVwGrgiZ3e0AnbzGpFDBUvuXdGUlnQxq2eHBF3A6SfLbs6A0jaHZgK/Ca3+fjUVPIFSdMmuqEfOppZzRSvOUfEKNBymA1JPwKe0mTXJ9uKSNoW+CZwaERsSJuPAn5PlsRHgU8Ax413HSdsM6uVoRLHw46IV7XaJ+kPkraNiLtTQl7d4rjNgQuBT0XEVblr350W10r6OvCxieJxk4iZ1cxGe9NxEXBoWj4U+I/GAyRNBb4PfCMizm/Yt236KbL27xsnuqETtpnVykYcS+QEYB9JtwH7pHUkjUg6PR3zFuBlwGFNuu+dk94avwHYBvjsRDd0k4iZ1czGedMxIu4lGxSvcfsy4D1p+Wzg7Bbn793uPZ2wzaxW/Gq6mVlF1PnVdEVEv2MoTNKC1A1n4AxqbI6rPYMaFwxubIMaVx1V7aFjO53aN7ZBjc1xtWdQ44LBjW1Q46qdqiVsM7NJywnbzKwiqpawB7mdbFBjc1ztGdS4YHBjG9S4aqdSDx3NzCazqtWwzcwmLSdsM7OKqF3ClrSjpLeVeL1jJU04ilaT8+ZKem2312m45paSPjDBMTtKajqIjKQfSxrpJoYySDpOUstR0MysuUombEnjvaG5I1Bawu7CXOC1Ex7Vni2BcRP2oJM0HBFHR8SP+h2LWdX0PWFLOiTNuHCdpG9K2k/Sf0m6RtKPJD05HXespFFJ/wl8I9Ukfyrp6lRenC55AvDSNCrWER3G9ElJt6bBy3dO23aS9ENJv0z3fVbafqakr6Rtv5b0ujSk4nHAW1McYxNv7pJquSskfbiD0E4AdkrX/IKkJemz3yDpgNxxUySdlX6vF0jatMln3DdNDnq1pPMlbdZBPI3X3FHSrxrvLekOSUdL+hlwYPqdvTmds5ukK9O//y8kzZQ0LOnzkpam67y329gKxL5butd0SU9QNmnqf+v1fQvE9RlJh+fWj+/wv53SSXpfbgS62yVd1u+Yai8i+laAXYFbgW3S+lbALB7rvfIe4MS0fCzwS2BGWt8UmJ6W5wDL0vIrgP/XRUwvJBvucFNgc2A52cDiS4A56Zg9gEvT8pnAD8m+/OYAK4HpwGHAKbnrHgtcCUwjG0rxXmCTNmPbEbgxLU8BNk/L26Q4lY4J4CVp3xnAx9Lyj4GRdPxPgCek7Z8Aji7h37PpvYE7gI/njjsTeDPZTBsrgN3S9s3T51pANtg76fe1DJi9Ef57/Czwv4FTgaP6+f+Nht/p1Wl5iGx6qa37HVdDjJsAPwX263csdS/9Hvxpb+CCiLgHICLWSHoO8J00uPdU4Pbc8Ysi4qG0vAlwShpbdj3wzJJieinw/Yh4EEDSIrIE/GLg/NxIYPn5186LbNqf2yStAJ7V4toXRsRashkmVgNPJkvwnRDwL5JeBmwAtkvXA7grIq5Iy2cDHyZLRGP2BHYBrkifZyrw8w7jaNTs3gDfaXLszsDdEbEUICL+AlntH3juWC0c2ILsy/D2Jtco03HAUuBhHou7ryLiDkn3Sno+2b/vNZEN6zlIvkhWgflBvwOpu34nbJHVyPJOBk6KiEWSXkFWMx3zQG75COAPwPPIah4PlxhXY0xDwH0RMbfZwU2Ob9W5fW1ueT3d/f7fTjb78gsj4lFJd5B9sRSJR8DiiJjfxf1baXXvBxoPpPm//9j2D0XEJWUGVsBWwGZklYHpNI+5H04n+4vtKWR/tQwMSYcBTwMW9jmUSaHfbdhLgLdI2hpA0lZktanfpf2HtjoxHXd3qtm+A/42puL9wMwuYvoJ8AZJMyTNBPYDHgRul3RgilOSnpc750BJQ5J2Ap5O1szTbRzN5K+5BbA6Jeu9yP5PM2YHSS9Ky/OBnzVc5yrgJZKeAZDamcv6C2Wie+f9CvgHSbulOGYqe6B8CfB+SZuk7c+U9ISS4hvPKPDPwDnAv22E+xX1fWAesBvZ72YgSHohWZPXwfHYxLLWQ31N2BFxE3A8cLmk64CTyGrU50v6KXDPOKd/GThU0lVkzSFjtaHrgXXpIVbbDx0j4mqyP9+vBb5L1jYHWY323SnOm4D8Q75bgcuBi4H3RcTDwGVkDxnzDx27kv4UvkJZt725wIikZSm2X+UOvYXsd3M9Wa3x3xuu80eyGtu30zFX0boZp13j3rshjkeAtwInp9/rYrKa7enAzcDV6bOeRo//GpR0CLAuIr5F9nB3N0ltzwjSC+n3dBlZ09v6fseTs5Ds3/iy9N/56ROdYN3xq+ldknQm2UPOC/odS79J2pHsd9H33hV1ImkIuBo4MCJu63c81j/9bhIxs3FI2oWsB9ASJ2tzDdvMrCJcwzYzqwgnbDOzinDCNjOrCCdsM7OKcMI2M6uI/w+y0/jBhSy9aAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "corr = df.corr()\n",
    "\n",
    "sns.heatmap(corr, \n",
    "        xticklabels=corr.columns,\n",
    "        yticklabels=corr.columns,\n",
    "        cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a lot of correlation between our features. \n",
    "\n",
    "In particular, we see carat, the weight of the diamond, is highly correlated with the dimensions. Price seems to be most related to the size of the diamond."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "carat    1.000000\n",
       "depth    0.028224\n",
       "table    0.181618\n",
       "price    0.921591\n",
       "x        0.975094\n",
       "y        0.951722\n",
       "z        0.953387\n",
       "Name: carat, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr['carat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x,y,z, and price all have correlations of > 90 percent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at our categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['carat', 'cut', 'color', 'clarity', 'depth', 'table', 'price', 'x', 'y',\n",
       "       'z'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ideal        21551\n",
       "Premium      13791\n",
       "Very Good    12082\n",
       "Good          4906\n",
       "Fair          1610\n",
       "Name: cut, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.cut.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our target variable. We see that most of our cuts are ideal..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3995365220615499"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "21551/len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed ~40 percent are ideal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "G    11292\n",
       "E     9797\n",
       "F     9542\n",
       "H     8304\n",
       "D     6775\n",
       "I     5422\n",
       "J     2808\n",
       "Name: color, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.color.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "G,H,E are the most common colors. This is actually an ordinal variable since D indicates best color and each color after that is worse. Most colors seem to be in the middle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SI1     13065\n",
       "VS2     12258\n",
       "SI2      9194\n",
       "VS1      8171\n",
       "VVS2     5066\n",
       "VVS1     3655\n",
       "IF       1790\n",
       "I1        741\n",
       "Name: clarity, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.clarity.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is also a ordered categorical variable. From the description above the order is: I1 (worst), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see most values are in the middle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will graph these after our data prep step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cut</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fair</th>\n",
       "      <td>1.046137</td>\n",
       "      <td>64.041677</td>\n",
       "      <td>59.053789</td>\n",
       "      <td>4358.757764</td>\n",
       "      <td>6.246894</td>\n",
       "      <td>6.182652</td>\n",
       "      <td>3.982770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Good</th>\n",
       "      <td>0.849185</td>\n",
       "      <td>62.365879</td>\n",
       "      <td>58.694639</td>\n",
       "      <td>3928.864452</td>\n",
       "      <td>5.838785</td>\n",
       "      <td>5.850744</td>\n",
       "      <td>3.639507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ideal</th>\n",
       "      <td>0.702837</td>\n",
       "      <td>61.709401</td>\n",
       "      <td>55.951668</td>\n",
       "      <td>3457.541970</td>\n",
       "      <td>5.507451</td>\n",
       "      <td>5.520080</td>\n",
       "      <td>3.401448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Premium</th>\n",
       "      <td>0.891955</td>\n",
       "      <td>61.264673</td>\n",
       "      <td>58.746095</td>\n",
       "      <td>4584.257704</td>\n",
       "      <td>5.973887</td>\n",
       "      <td>5.944879</td>\n",
       "      <td>3.647124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Very Good</th>\n",
       "      <td>0.806381</td>\n",
       "      <td>61.818275</td>\n",
       "      <td>57.956150</td>\n",
       "      <td>3981.759891</td>\n",
       "      <td>5.740696</td>\n",
       "      <td>5.770026</td>\n",
       "      <td>3.559801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              carat      depth      table        price         x         y  \\\n",
       "cut                                                                          \n",
       "Fair       1.046137  64.041677  59.053789  4358.757764  6.246894  6.182652   \n",
       "Good       0.849185  62.365879  58.694639  3928.864452  5.838785  5.850744   \n",
       "Ideal      0.702837  61.709401  55.951668  3457.541970  5.507451  5.520080   \n",
       "Premium    0.891955  61.264673  58.746095  4584.257704  5.973887  5.944879   \n",
       "Very Good  0.806381  61.818275  57.956150  3981.759891  5.740696  5.770026   \n",
       "\n",
       "                  z  \n",
       "cut                  \n",
       "Fair       3.982770  \n",
       "Good       3.639507  \n",
       "Ideal      3.401448  \n",
       "Premium    3.647124  \n",
       "Very Good  3.559801  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('cut').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we group by cut, the most significant difference seems to be carat. The weight of cuts that are simply fair, are around 1 while ideal is around .7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the order of the rows isn't in order (ideal is the 3rd one.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal = df[df.cut == 'Ideal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "G    0.226625\n",
       "E    0.181105\n",
       "F    0.177532\n",
       "H    0.144541\n",
       "D    0.131502\n",
       "I    0.097118\n",
       "J    0.041576\n",
       "Name: color, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ideal.color.value_counts()/len(ideal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "G    0.209344\n",
       "E    0.181628\n",
       "F    0.176900\n",
       "H    0.153949\n",
       "D    0.125603\n",
       "I    0.100519\n",
       "J    0.052058\n",
       "Name: color, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.color.value_counts()/len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like color isn't so predictive of the color as these values are all around the same. This also logically makes sense as color isn't really logically related to how well the person will cut a diamond."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SI1     0.242214\n",
       "VS2     0.227253\n",
       "SI2     0.170449\n",
       "VS1     0.151483\n",
       "VVS2    0.093919\n",
       "VVS1    0.067760\n",
       "IF      0.033185\n",
       "I1      0.013737\n",
       "Name: clarity, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.clarity.value_counts()/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VS2     0.235302\n",
       "SI1     0.198691\n",
       "VS1     0.166535\n",
       "VVS2    0.120922\n",
       "SI2     0.120551\n",
       "VVS1    0.094984\n",
       "IF      0.056239\n",
       "I1      0.006775\n",
       "Name: clarity, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ideal.clarity.value_counts()/len(ideal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "refer: I1 (worst), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The percentage of high IF is 2 percent higher and VVS1 is around 3 percent higher. These are pretty big differences since the values had low percentages to start with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ideal        21551\n",
       "Premium      13791\n",
       "Very Good    12082\n",
       "Good          4906\n",
       "Fair          1610\n",
       "Name: cut, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.cut.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "_map =   {\n",
    "    \"Ideal\" : 1,\n",
    "    \"Premium\" : 2,\n",
    "    \"Very Good\" : 3,\n",
    "    \"Good\" : 4,\n",
    "    \"Fair\" : 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "cuts = df['cut'].map(_map).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "numericalCols = ['carat','depth', 'table', 'price', 'x', 'y','z' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to calculate the correlation between these variables and our target, we can use f scores. https://dzone.com/articles/correlation-between-categorical-and-continuous-var-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f score for carat is 495.69425927416324 with a p value of 0.0\n",
      "The f score for depth is 1897.4085865319598 with a p value of 0.0\n",
      "The f score for table is 6367.179433767924 with a p value of 0.0\n",
      "The f score for price is 175.68871735080606 with a p value of 8.42830730759452e-150\n",
      "The f score for x is 489.3942696199593 with a p value of 0.0\n",
      "The f score for y is 395.7202028355892 with a p value of 0.0\n",
      "The f score for z is 489.39820841970567 with a p value of 0.0\n",
      "489.39820841970567\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "for col in numericalCols:\n",
    "    F, p = stats.f_oneway(df[df.cut=='Ideal'][col],\n",
    "                      df[df.cut=='Premium'][col],\n",
    "                      df[df.cut=='Very Good'][col],\n",
    "                        df[df.cut=='Good'][col],\n",
    "                      df[df.cut=='Fair'][col])\n",
    "    print(f'The f score for {col} is {F} with a p value of {p}' )\n",
    "\n",
    "print(F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The higher the score, the more correltion there is. We see that all of these values have high correlations.\n",
    "\n",
    "1. Table and depth are the most significant - this makes sense as the table represents the width of the diamond at its longest point and depth represents how deep the diamond is. As we saw at https://www.diamonds.pro/education/cuts/ the proportions of the diamond are very important\n",
    "2. Price is the least important - We can see here for why https://beyond4cs.com/cut/effects-on-pricing/#:~:text=At%20the%20heart%20of%20it%2C%20the%20carat%20weight,diamond%20can%20drastically%20increase%20or%20decrease%20its%20value\n",
    "Although it is true that the price increases as the cut is better, this is assuming that the cost of the carat is constant. Because in our dataset the carat variable is fluctuating we expect to see some correlation but it may not be as high as it could be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA Summary:\n",
    "        Our target variable cut has around 40 percent ideal. The better cuts all have higher frequency. \n",
    "        Our target variable is correlated with most of our other features. \n",
    "        Many of our numerical variables are correlated with each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to ordinal encode our clarity variable. Color we will drop as we saw from our eda isn't so insightful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['carat', 'cut', 'color', 'clarity', 'depth', 'table', 'price', 'x', 'y',\n",
       "       'z'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SI1     13065\n",
       "VS2     12258\n",
       "SI2      9194\n",
       "VS1      8171\n",
       "VVS2     5066\n",
       "VVS1     3655\n",
       "IF       1790\n",
       "I1        741\n",
       "Name: clarity, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.clarity.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall - I1 (worst), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "_map =   {\n",
    "    \"I1\" : 1,\n",
    "    \"SI2\" : 2,\n",
    "    \"SI1\" : 3,\n",
    "    \"VS2\" : 4,\n",
    "    \"VS1\" : 5,\n",
    "    \"VVS2\" :6,\n",
    "    \"VVS1\" : 7,\n",
    "    \"IF\" : 8,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clarity'] = df['clarity'].map(_map).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's drop the outlier rows we mentioned earlier. This is a low proportion of our total size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([49189, 24067,48410], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['carat', 'cut', 'color', 'clarity', 'depth', 'table', 'price', 'x', 'y',\n",
       "       'z'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a lot of features that are very correlated. This might make the model longer to train. I therefore am going to drop some of the correlated variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will also drop the color feature though since we saw in our eda that there is no significant difference with this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('color', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1abbe812518>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "corr = df.corr()\n",
    "\n",
    "sns.heatmap(corr, \n",
    "        xticklabels=corr.columns,\n",
    "        yticklabels=corr.columns,\n",
    "        cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of values look around 1 but let's get the actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "carat      0.975093\n",
       "cut        0.125575\n",
       "clarity   -0.371963\n",
       "depth     -0.025213\n",
       "table      0.195343\n",
       "price      0.884425\n",
       "x          1.000000\n",
       "y          0.998339\n",
       "z          0.986193\n",
       "Name: x, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "carat      0.974439\n",
       "cut        0.125118\n",
       "clarity   -0.366848\n",
       "depth     -0.028355\n",
       "table      0.189169\n",
       "price      0.886225\n",
       "x          0.998339\n",
       "y          1.000000\n",
       "z          0.985587\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "carat      0.968554\n",
       "cut        0.151104\n",
       "clarity   -0.373012\n",
       "depth      0.096625\n",
       "table      0.154297\n",
       "price      0.874910\n",
       "x          0.986193\n",
       "y          0.985587\n",
       "z          1.000000\n",
       "Name: z, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr['z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "carat      1.000000\n",
       "cut        0.134980\n",
       "clarity   -0.352800\n",
       "depth      0.028322\n",
       "table      0.181618\n",
       "price      0.921585\n",
       "x          0.975093\n",
       "y          0.974439\n",
       "z          0.968554\n",
       "Name: carat, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr['carat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['carat', 'cut', 'clarity', 'depth', 'table', 'price', 'x', 'y', 'z'], dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that carat is explaining over 95 percent of the variance in x,y,z and z. This makes sense as the larger the dimensions, the more the diamond weighs. Therefore, we won't be losing that much by dropping these columns. Price also has a large correlation as generally the cost is by carat however I think we should keep it as we have so few columns and price does change as based on the cut as we saw in the article above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['x','y','z'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that a side effect of this is that we don't need to deal with the rows with 0 dimensions, although as mentioned earlier these rows aren't the biggest deal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also scale the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['carat', 'cut', 'clarity', 'depth', 'table', 'price'], dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "numericalCols = ['carat', 'depth', 'price', 'table']\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df[numericalCols])\n",
    "scaled = pd.DataFrame(scaler.transform(df[numericalCols]))\n",
    "scaled.columns = numericalCols\n",
    "for col in numericalCols:\n",
    "    df[col] = scaled[col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepped Data Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aside from the columns we dropped, we used an ordinal encoder to convert the color column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    13065\n",
       "4    12258\n",
       "2     9193\n",
       "5     8169\n",
       "6     5066\n",
       "7     3655\n",
       "8     1790\n",
       "1      741\n",
       "Name: clarity, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clarity'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing these too the numbers we saw above in our eda we see that these numbers match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1abbf2e4d68>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['clarity'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x000001ABBF2E4668>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001ABBEB3C1D0>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x000001ABBEB62748>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001ABBEB87CC0>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[numericalCols].hist(figsize = (15,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also see the effect of our standard scaler here. We have some negative values which logically don't make sense but the model would be able to handle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will be constructing different feed-forward, back propagating neural network models. My computer is not that strong so we will start with a basic model and slowly scale upwards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's split our data into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = df['cut']\n",
    "x= df.drop(['cut'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['carat', 'clarity', 'depth', 'table', 'price'], dtype='object')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11284</th>\n",
       "      <td>0.531810</td>\n",
       "      <td>4</td>\n",
       "      <td>0.454102</td>\n",
       "      <td>0.690413</td>\n",
       "      <td>0.261267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44733</th>\n",
       "      <td>-0.480873</td>\n",
       "      <td>4</td>\n",
       "      <td>0.872922</td>\n",
       "      <td>0.242881</td>\n",
       "      <td>-0.580477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38159</th>\n",
       "      <td>-0.966116</td>\n",
       "      <td>7</td>\n",
       "      <td>0.314495</td>\n",
       "      <td>-0.652184</td>\n",
       "      <td>-0.731630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.215347</td>\n",
       "      <td>3</td>\n",
       "      <td>0.733315</td>\n",
       "      <td>0.690413</td>\n",
       "      <td>-0.266139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>0.721688</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.941966</td>\n",
       "      <td>0.242881</td>\n",
       "      <td>0.598416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          carat  clarity     depth     table     price\n",
       "11284  0.531810        4  0.454102  0.690413  0.261267\n",
       "44733 -0.480873        4  0.872922  0.242881 -0.580477\n",
       "38159 -0.966116        7  0.314495 -0.652184 -0.731630\n",
       "860    0.215347        3  0.733315  0.690413 -0.266139\n",
       "15795  0.721688        3 -0.941966  0.242881  0.598416"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    21549\n",
       "2    13789\n",
       "3    12080\n",
       "4     4906\n",
       "5     1610\n",
       "Name: cut, dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts() # we actually transformed this variable above when we did our eda to be numerical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to encode remap these to integers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note we have 6 columns and our target variable has 5 values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuitivly, I would think since we aren't using so many features we shouldn't need so many layers. Let's start with 1 dense layer with a relu activation function and a layer with a softmax function to generate the output. Let's use 36 as that is the number of features squared which sounds like a good starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "impor keras\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(36, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(6, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "carat      0\n",
       "clarity    0\n",
       "depth      0\n",
       "table      0\n",
       "price      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "43147/43147 [==============================] - 5s 114us/step - loss: 1.3002 - acc: 0.4635 0s - loss: 1.3083 -\n",
      "Epoch 2/3\n",
      "43147/43147 [==============================] - ETA: 0s - loss: 1.2507 - acc: 0.484 - 4s 82us/step - loss: 1.2506 - acc: 0.4843\n",
      "Epoch 3/3\n",
      "43147/43147 [==============================] - 3s 74us/step - loss: 1.2353 - acc: 0.4922: 1s - loss: 1.2403 - acc: 0. - ETA: 1s - loss\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train.values, y_train.values, epochs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "scores = model.predict_classes(X_train)\n",
    "print(metrics.classification_report(y_train,scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember from our mapping above...\n",
    "1 is ideal\n",
    "5 is the worst.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simple model has an accuracy around .49. It is fairly quick to run. We can use this as a baseline and start adding more layers to this as we see this isn't complicated enough. First though, we see that if we increase the number of epochs we might be able to increase our score as it will minimize the loss function more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuildModel(n_layers, nodes):\n",
    "    model = keras.models.Sequential()\n",
    "    for i in range(n_layers):\n",
    "        model.add(keras.layers.Dense(nodes, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(6, activation=\"softmax\"))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BuildModel(5, 36) # 5 layer with 36 nodes. 36 since 36 is the number of features squared. 5 layers so we have 5 x as many layers as the previous. \n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use 100 epochs as that is not too long but also not too short. We can see if our accuracy score is still going up at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "43147/43147 [==============================] - 4s 97us/step - loss: 1.0704 - acc: 0.5555\n",
      "Epoch 2/100\n",
      "43147/43147 [==============================] - 4s 96us/step - loss: 1.0701 - acc: 0.5549\n",
      "Epoch 3/100\n",
      "43147/43147 [==============================] - 4s 96us/step - loss: 1.0704 - acc: 0.5542\n",
      "Epoch 4/100\n",
      "43147/43147 [==============================] - 4s 96us/step - loss: 1.0696 - acc: 0.5552\n",
      "Epoch 5/100\n",
      "43147/43147 [==============================] - 4s 97us/step - loss: 1.0687 - acc: 0.5541\n",
      "Epoch 6/100\n",
      "43147/43147 [==============================] - 4s 96us/step - loss: 1.0680 - acc: 0.5563\n",
      "Epoch 7/100\n",
      "43147/43147 [==============================] - 4s 97us/step - loss: 1.0673 - acc: 0.5568\n",
      "Epoch 8/100\n",
      "43147/43147 [==============================] - 4s 96us/step - loss: 1.0676 - acc: 0.5557\n",
      "Epoch 9/100\n",
      "43147/43147 [==============================] - 4s 103us/step - loss: 1.0667 - acc: 0.5567 1s - loss\n",
      "Epoch 10/100\n",
      "43147/43147 [==============================] - 4s 97us/step - loss: 1.0680 - acc: 0.5556\n",
      "Epoch 11/100\n",
      "43147/43147 [==============================] - 4s 98us/step - loss: 1.0665 - acc: 0.5573: 0s - loss: 1.0665 - acc:\n",
      "Epoch 12/100\n",
      "43147/43147 [==============================] - 4s 98us/step - loss: 1.0656 - acc: 0.5556\n",
      "Epoch 13/100\n",
      "43147/43147 [==============================] - 5s 112us/step - loss: 1.0661 - acc: 0.5556\n",
      "Epoch 14/100\n",
      "43147/43147 [==============================] - 4s 101us/step - loss: 1.0653 - acc: 0.5577\n",
      "Epoch 15/100\n",
      "43147/43147 [==============================] - 4s 90us/step - loss: 1.0647 - acc: 0.5562\n",
      "Epoch 16/100\n",
      "43147/43147 [==============================] - 4s 98us/step - loss: 1.0643 - acc: 0.5586\n",
      "Epoch 17/100\n",
      "43147/43147 [==============================] - 4s 97us/step - loss: 1.0637 - acc: 0.5583: 0s - loss: 1.\n",
      "Epoch 18/100\n",
      "43147/43147 [==============================] - 5s 113us/step - loss: 1.0638 - acc: 0.5572\n",
      "Epoch 19/100\n",
      "43147/43147 [==============================] - 5s 114us/step - loss: 1.0636 - acc: 0.5585\n",
      "Epoch 20/100\n",
      "43147/43147 [==============================] - 4s 101us/step - loss: 1.0629 - acc: 0.5565\n",
      "Epoch 21/100\n",
      "43147/43147 [==============================] - 4s 101us/step - loss: 1.0622 - acc: 0.5588 ETA: 1s\n",
      "Epoch 22/100\n",
      "43147/43147 [==============================] - 4s 102us/step - loss: 1.0616 - acc: 0.5577\n",
      "Epoch 23/100\n",
      "43147/43147 [==============================] - 4s 103us/step - loss: 1.0617 - acc: 0.5575\n",
      "Epoch 24/100\n",
      "43147/43147 [==============================] - 4s 102us/step - loss: 1.0610 - acc: 0.5580\n",
      "Epoch 25/100\n",
      "43147/43147 [==============================] - 4s 103us/step - loss: 1.0603 - acc: 0.5600 2s - loss: \n",
      "Epoch 26/100\n",
      "43147/43147 [==============================] - 4s 101us/step - loss: 1.0608 - acc: 0.5604\n",
      "Epoch 27/100\n",
      "43147/43147 [==============================] - 4s 99us/step - loss: 1.0605 - acc: 0.5606\n",
      "Epoch 28/100\n",
      "43147/43147 [==============================] - 5s 111us/step - loss: 1.0590 - acc: 0.5595\n",
      "Epoch 29/100\n",
      "43147/43147 [==============================] - 4s 103us/step - loss: 1.0593 - acc: 0.5609 1s - loss:  - ETA: 0s - loss: 1.0582 \n",
      "Epoch 30/100\n",
      "43147/43147 [==============================] - 4s 104us/step - loss: 1.0593 - acc: 0.5590\n",
      "Epoch 31/100\n",
      "43147/43147 [==============================] - 4s 102us/step - loss: 1.0587 - acc: 0.5604\n",
      "Epoch 32/100\n",
      "43147/43147 [==============================] - 5s 106us/step - loss: 1.0581 - acc: 0.5615\n",
      "Epoch 33/100\n",
      "43147/43147 [==============================] - 4s 98us/step - loss: 1.0582 - acc: 0.5602: 0s - loss: 1.0580\n",
      "Epoch 34/100\n",
      "43147/43147 [==============================] - 4s 101us/step - loss: 1.0565 - acc: 0.5593 0s - loss: 1.0571 \n",
      "Epoch 35/100\n",
      "43147/43147 [==============================] - 4s 104us/step - loss: 1.0580 - acc: 0.5602\n",
      "Epoch 36/100\n",
      "43147/43147 [==============================] - 5s 105us/step - loss: 1.0564 - acc: 0.5614 1s - loss - ETA: 0s - loss: 1.0552 - a\n",
      "Epoch 37/100\n",
      "43147/43147 [==============================] - 5s 127us/step - loss: 1.0566 - acc: 0.5602\n",
      "Epoch 38/100\n",
      "43147/43147 [==============================] - 5s 116us/step - loss: 1.0559 - acc: 0.5598\n",
      "Epoch 39/100\n",
      "43147/43147 [==============================] - 4s 99us/step - loss: 1.0560 - acc: 0.5612\n",
      "Epoch 40/100\n",
      "43147/43147 [==============================] - 5s 107us/step - loss: 1.0557 - acc: 0.5615\n",
      "Epoch 41/100\n",
      "43147/43147 [==============================] - 5s 117us/step - loss: 1.0553 - acc: 0.5602 2s - loss: 1.0547 - \n",
      "Epoch 42/100\n",
      "43147/43147 [==============================] - 5s 114us/step - loss: 1.0545 - acc: 0.5605\n",
      "Epoch 43/100\n",
      "43147/43147 [==============================] - 5s 105us/step - loss: 1.0544 - acc: 0.5616\n",
      "Epoch 44/100\n",
      "43147/43147 [==============================] - 5s 117us/step - loss: 1.0541 - acc: 0.5598\n",
      "Epoch 45/100\n",
      "43147/43147 [==============================] - 5s 104us/step - loss: 1.0541 - acc: 0.5619\n",
      "Epoch 46/100\n",
      "43147/43147 [==============================] - 5s 108us/step - loss: 1.0541 - acc: 0.5607 0s - loss: 1.0538 - acc: 0.56 - ETA: 0s - loss: 1.0541 - acc: 0.56 - ETA: 0s - loss: 1.0544 - acc: 0.56\n",
      "Epoch 47/100\n",
      "43147/43147 [==============================] - 5s 111us/step - loss: 1.0534 - acc: 0.5624\n",
      "Epoch 48/100\n",
      "43147/43147 [==============================] - 5s 108us/step - loss: 1.0529 - acc: 0.5631\n",
      "Epoch 49/100\n",
      "43147/43147 [==============================] - 4s 102us/step - loss: 1.0533 - acc: 0.5637 3s - lo\n",
      "Epoch 50/100\n",
      "43147/43147 [==============================] - ETA: 0s - loss: 1.0512 - acc: 0.563 - 5s 105us/step - loss: 1.0519 - acc: 0.5632\n",
      "Epoch 51/100\n",
      "43147/43147 [==============================] - 4s 99us/step - loss: 1.0529 - acc: 0.5617\n",
      "Epoch 52/100\n",
      "43147/43147 [==============================] - 5s 106us/step - loss: 1.0522 - acc: 0.5604 3s - loss: 1.0641 - acc - ETA: 2s - loss: 1.0555 - acc:  - ETA: 2s - loss: 1.0533 - acc: 0.5 - ETA: 2s - loss: 1.0519 - acc: 0.562 - ETA: 2s - loss: 1.0516 - a -\n",
      "Epoch 53/100\n",
      "43147/43147 [==============================] - 4s 103us/step - loss: 1.0510 - acc: 0.5642\n",
      "Epoch 54/100\n",
      "43147/43147 [==============================] - 5s 109us/step - loss: 1.0516 - acc: 0.5638\n",
      "Epoch 55/100\n",
      "43147/43147 [==============================] - 4s 103us/step - loss: 1.0510 - acc: 0.5630\n",
      "Epoch 56/100\n",
      "43147/43147 [==============================] - 5s 117us/step - loss: 1.0513 - acc: 0.5635 1s - loss\n",
      "Epoch 57/100\n",
      "43147/43147 [==============================] - 5s 111us/step - loss: 1.0507 - acc: 0.5656\n",
      "Epoch 58/100\n",
      "43147/43147 [==============================] - 4s 102us/step - loss: 1.0511 - acc: 0.5632\n",
      "Epoch 59/100\n",
      "43147/43147 [==============================] - 4s 101us/step - loss: 1.0497 - acc: 0.5636\n",
      "Epoch 60/100\n",
      "43147/43147 [==============================] - 4s 97us/step - loss: 1.0509 - acc: 0.5632\n",
      "Epoch 61/100\n",
      "43147/43147 [==============================] - 4s 99us/step - loss: 1.0499 - acc: 0.5630: 0s - loss: 1.0491 - acc\n",
      "Epoch 62/100\n",
      "43147/43147 [==============================] - 4s 99us/step - loss: 1.0496 - acc: 0.5649\n",
      "Epoch 63/100\n",
      "43147/43147 [==============================] - 4s 100us/step - loss: 1.0496 - acc: 0.5645\n",
      "Epoch 64/100\n",
      "43147/43147 [==============================] - 4s 100us/step - loss: 1.0489 - acc: 0.5636 3s - loss: 1.0595 - acc: 0 - \n",
      "Epoch 65/100\n",
      "43147/43147 [==============================] - 4s 103us/step - loss: 1.0488 - acc: 0.5648 3s - loss - ETA: 2s - loss: 1.052 - ETA: \n",
      "Epoch 66/100\n",
      "43147/43147 [==============================] - 4s 96us/step - loss: 1.0489 - acc: 0.5648\n",
      "Epoch 67/100\n",
      "43147/43147 [==============================] - 4s 99us/step - loss: 1.0486 - acc: 0.5650\n",
      "Epoch 68/100\n",
      "43147/43147 [==============================] - 4s 97us/step - loss: 1.0485 - acc: 0.5650\n",
      "Epoch 69/100\n",
      "43147/43147 [==============================] - 4s 99us/step - loss: 1.0483 - acc: 0.5647\n",
      "Epoch 70/100\n",
      "43147/43147 [==============================] - 4s 96us/step - loss: 1.0475 - acc: 0.5656\n",
      "Epoch 71/100\n",
      "43147/43147 [==============================] - 5s 106us/step - loss: 1.0480 - acc: 0.5633\n",
      "Epoch 72/100\n",
      "43147/43147 [==============================] - 5s 109us/step - loss: 1.0468 - acc: 0.5631\n",
      "Epoch 73/100\n",
      "43147/43147 [==============================] - 4s 99us/step - loss: 1.0469 - acc: 0.5660: 1s - los\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43147/43147 [==============================] - 4s 104us/step - loss: 1.0463 - acc: 0.5650\n",
      "Epoch 75/100\n",
      "43147/43147 [==============================] - ETA: 0s - loss: 1.0467 - acc: 0.563 - 5s 114us/step - loss: 1.0471 - acc: 0.5631\n",
      "Epoch 76/100\n",
      "43147/43147 [==============================] - 5s 111us/step - loss: 1.0466 - acc: 0.5659 3s - loss: 1.0 - ETA: 2s - loss - ETA: 1s - loss: 1.0477 - acc: 0.56 - ETA: 1s - loss: 1.0480 - acc: - ETA: 1s - loss:\n",
      "Epoch 77/100\n",
      "43147/43147 [==============================] - 4s 101us/step - loss: 1.0464 - acc: 0.5645\n",
      "Epoch 78/100\n",
      "43147/43147 [==============================] - 4s 98us/step - loss: 1.0467 - acc: 0.5640\n",
      "Epoch 79/100\n",
      "43147/43147 [==============================] - 4s 101us/step - loss: 1.0451 - acc: 0.5640\n",
      "Epoch 80/100\n",
      "43147/43147 [==============================] - 5s 106us/step - loss: 1.0457 - acc: 0.5649\n",
      "Epoch 81/100\n",
      "43147/43147 [==============================] - 4s 98us/step - loss: 1.0456 - acc: 0.5669\n",
      "Epoch 82/100\n",
      "43147/43147 [==============================] - 4s 98us/step - loss: 1.0448 - acc: 0.5660\n",
      "Epoch 83/100\n",
      "43147/43147 [==============================] - 4s 96us/step - loss: 1.0456 - acc: 0.5661\n",
      "Epoch 84/100\n",
      "43147/43147 [==============================] - 4s 98us/step - loss: 1.0445 - acc: 0.5663\n",
      "Epoch 85/100\n",
      "43147/43147 [==============================] - 4s 98us/step - loss: 1.0450 - acc: 0.5679\n",
      "Epoch 86/100\n",
      "43147/43147 [==============================] - 5s 110us/step - loss: 1.0437 - acc: 0.5669\n",
      "Epoch 87/100\n",
      "43147/43147 [==============================] - 4s 103us/step - loss: 1.0446 - acc: 0.5638\n",
      "Epoch 88/100\n",
      "43147/43147 [==============================] - 4s 104us/step - loss: 1.0441 - acc: 0.5665 0s - loss: 1.045\n",
      "Epoch 89/100\n",
      "43147/43147 [==============================] - 4s 103us/step - loss: 1.0444 - acc: 0.5653\n",
      "Epoch 90/100\n",
      "43147/43147 [==============================] - 4s 100us/step - loss: 1.0439 - acc: 0.5645 2s - loss: 1.0424 - acc: 0.56 - ETA: 2s - lo - ETA: 0s - loss: 1.0413\n",
      "Epoch 91/100\n",
      "43147/43147 [==============================] - 4s 101us/step - loss: 1.0430 - acc: 0.5653 1s - l\n",
      "Epoch 92/100\n",
      "43147/43147 [==============================] - 4s 98us/step - loss: 1.0425 - acc: 0.5673\n",
      "Epoch 93/100\n",
      "43147/43147 [==============================] - 4s 100us/step - loss: 1.0428 - acc: 0.5672 ETA: 0s - loss: 1.042\n",
      "Epoch 94/100\n",
      "43147/43147 [==============================] - 4s 99us/step - loss: 1.0420 - acc: 0.5669: 1s - loss: 1.0 - ETA: 0s - loss: 1.0392 \n",
      "Epoch 95/100\n",
      "43147/43147 [==============================] - 4s 100us/step - loss: 1.0426 - acc: 0.5666\n",
      "Epoch 96/100\n",
      "43147/43147 [==============================] - 4s 102us/step - loss: 1.0422 - acc: 0.5662 2s - loss: 1.0422 - acc:  - ETA\n",
      "Epoch 97/100\n",
      "43147/43147 [==============================] - 5s 106us/step - loss: 1.0425 - acc: 0.5672\n",
      "Epoch 98/100\n",
      "43147/43147 [==============================] - 4s 97us/step - loss: 1.0426 - acc: 0.5670\n",
      "Epoch 99/100\n",
      "43147/43147 [==============================] - 4s 98us/step - loss: 1.0415 - acc: 0.5664\n",
      "Epoch 100/100\n",
      "43147/43147 [==============================] - 5s 113us/step - loss: 1.0420 - acc: 0.5660\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train.values, y_train.values, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model has better accuracy score at around .55. We see that we can actually increase the number of epochs isn't dramatically improving our scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.80      0.69     17206\n",
      "           2       0.49      0.59      0.54     11049\n",
      "           3       0.49      0.23      0.31      9722\n",
      "           4       0.68      0.30      0.41      3912\n",
      "           5       0.86      0.50      0.64      1258\n",
      "\n",
      "    accuracy                           0.57     43147\n",
      "   macro avg       0.63      0.49      0.52     43147\n",
      "weighted avg       0.57      0.57      0.54     43147\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = model.predict_classes(X_train.values)\n",
    "print(metrics.classification_report(y_train,scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 2, 1, ..., 1, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Our scores are slightly better with this model. The main reason why may simply be increasing the number of epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try doubling the number of layers and see how that impacts the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BuildModel(10, 36) # 5 layer with 36 nodes. 36 since 36 is the number of features squared. 5 layers so we have 5 x as many layers as the previous. \n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use 100 epochs again so we could directly compare just how increasing the layers effects the model and also because past 100 the accuracy doesn't improve so much.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "43147/43147 [==============================] - 5s 110us/step - loss: 1.1100 - acc: 0.5386\n",
      "Epoch 2/100\n",
      "43147/43147 [==============================] - 5s 110us/step - loss: 1.1073 - acc: 0.5397\n",
      "Epoch 3/100\n",
      "43147/43147 [==============================] - 5s 110us/step - loss: 1.1041 - acc: 0.5420\n",
      "Epoch 4/100\n",
      "43147/43147 [==============================] - 5s 109us/step - loss: 1.1013 - acc: 0.5437\n",
      "Epoch 5/100\n",
      "43147/43147 [==============================] - 5s 111us/step - loss: 1.0993 - acc: 0.5446\n",
      "Epoch 6/100\n",
      "43147/43147 [==============================] - 5s 110us/step - loss: 1.0966 - acc: 0.5435\n",
      "Epoch 7/100\n",
      "43147/43147 [==============================] - 5s 122us/step - loss: 1.0951 - acc: 0.5456\n",
      "Epoch 8/100\n",
      "43147/43147 [==============================] - 5s 111us/step - loss: 1.0935 - acc: 0.5453\n",
      "Epoch 9/100\n",
      "43147/43147 [==============================] - 5s 110us/step - loss: 1.0903 - acc: 0.5481\n",
      "Epoch 10/100\n",
      "43147/43147 [==============================] - 5s 111us/step - loss: 1.0900 - acc: 0.5461\n",
      "Epoch 11/100\n",
      "43147/43147 [==============================] - 5s 111us/step - loss: 1.0880 - acc: 0.5490\n",
      "Epoch 12/100\n",
      "43147/43147 [==============================] - 5s 109us/step - loss: 1.0858 - acc: 0.5496\n",
      "Epoch 13/100\n",
      "43147/43147 [==============================] - 5s 109us/step - loss: 1.0849 - acc: 0.5501\n",
      "Epoch 14/100\n",
      "43147/43147 [==============================] - 5s 106us/step - loss: 1.0841 - acc: 0.5501\n",
      "Epoch 15/100\n",
      "43147/43147 [==============================] - 5s 109us/step - loss: 1.0819 - acc: 0.5505\n",
      "Epoch 16/100\n",
      "43147/43147 [==============================] - 5s 108us/step - loss: 1.0800 - acc: 0.5496\n",
      "Epoch 17/100\n",
      "43147/43147 [==============================] - 5s 107us/step - loss: 1.0809 - acc: 0.5506\n",
      "Epoch 18/100\n",
      "43147/43147 [==============================] - 5s 110us/step - loss: 1.0790 - acc: 0.5512\n",
      "Epoch 19/100\n",
      "43147/43147 [==============================] - 5s 110us/step - loss: 1.0773 - acc: 0.5501\n",
      "Epoch 20/100\n",
      "43147/43147 [==============================] - 5s 113us/step - loss: 1.0768 - acc: 0.5543\n",
      "Epoch 21/100\n",
      "43147/43147 [==============================] - 5s 119us/step - loss: 1.0766 - acc: 0.5544\n",
      "Epoch 22/100\n",
      "43147/43147 [==============================] - 5s 110us/step - loss: 1.0751 - acc: 0.5545 0s - loss: 1.0751\n",
      "Epoch 23/100\n",
      "43147/43147 [==============================] - 5s 109us/step - loss: 1.0740 - acc: 0.5542\n",
      "Epoch 24/100\n",
      "43147/43147 [==============================] - 5s 112us/step - loss: 1.0735 - acc: 0.5550\n",
      "Epoch 25/100\n",
      "43147/43147 [==============================] - 5s 110us/step - loss: 1.0736 - acc: 0.5548\n",
      "Epoch 26/100\n",
      "43147/43147 [==============================] - 5s 110us/step - loss: 1.0727 - acc: 0.5548\n",
      "Epoch 27/100\n",
      "43147/43147 [==============================] - 5s 110us/step - loss: 1.0713 - acc: 0.5559\n",
      "Epoch 28/100\n",
      "43147/43147 [==============================] - 5s 110us/step - loss: 1.0705 - acc: 0.5543\n",
      "Epoch 29/100\n",
      "43147/43147 [==============================] - 5s 108us/step - loss: 1.0707 - acc: 0.5561\n",
      "Epoch 30/100\n",
      "43147/43147 [==============================] - 5s 111us/step - loss: 1.0700 - acc: 0.5555\n",
      "Epoch 31/100\n",
      "43147/43147 [==============================] - 5s 108us/step - loss: 1.0687 - acc: 0.5582\n",
      "Epoch 32/100\n",
      "43147/43147 [==============================] - 5s 110us/step - loss: 1.0687 - acc: 0.5575\n",
      "Epoch 33/100\n",
      "43147/43147 [==============================] - 5s 109us/step - loss: 1.0681 - acc: 0.5572\n",
      "Epoch 34/100\n",
      "43147/43147 [==============================] - 5s 110us/step - loss: 1.0680 - acc: 0.5558\n",
      "Epoch 35/100\n",
      "43147/43147 [==============================] - 5s 115us/step - loss: 1.0672 - acc: 0.5561\n",
      "Epoch 36/100\n",
      "43147/43147 [==============================] - 4s 102us/step - loss: 1.0664 - acc: 0.5583\n",
      "Epoch 37/100\n",
      "43147/43147 [==============================] - 4s 92us/step - loss: 1.0664 - acc: 0.5577\n",
      "Epoch 38/100\n",
      "43147/43147 [==============================] - 5s 109us/step - loss: 1.0660 - acc: 0.5561\n",
      "Epoch 39/100\n",
      "43147/43147 [==============================] - 5s 109us/step - loss: 1.0652 - acc: 0.5577\n",
      "Epoch 40/100\n",
      "43147/43147 [==============================] - 5s 108us/step - loss: 1.0638 - acc: 0.5589\n",
      "Epoch 41/100\n",
      "43147/43147 [==============================] - 5s 109us/step - loss: 1.0640 - acc: 0.5577\n",
      "Epoch 42/100\n",
      "43147/43147 [==============================] - 5s 108us/step - loss: 1.0643 - acc: 0.5589\n",
      "Epoch 43/100\n",
      "43147/43147 [==============================] - 5s 108us/step - loss: 1.0631 - acc: 0.5594\n",
      "Epoch 44/100\n",
      "43147/43147 [==============================] - 5s 108us/step - loss: 1.0624 - acc: 0.5589\n",
      "Epoch 45/100\n",
      "43147/43147 [==============================] - 4s 104us/step - loss: 1.0624 - acc: 0.5588 1s -\n",
      "Epoch 46/100\n",
      "43147/43147 [==============================] - 5s 107us/step - loss: 1.0629 - acc: 0.5576\n",
      "Epoch 47/100\n",
      "43147/43147 [==============================] - 5s 115us/step - loss: 1.0607 - acc: 0.5598\n",
      "Epoch 48/100\n",
      "43147/43147 [==============================] - 5s 113us/step - loss: 1.0605 - acc: 0.5595\n",
      "Epoch 49/100\n",
      "43147/43147 [==============================] - 5s 118us/step - loss: 1.0608 - acc: 0.5594\n",
      "Epoch 50/100\n",
      "43147/43147 [==============================] - 5s 112us/step - loss: 1.0607 - acc: 0.5607\n",
      "Epoch 51/100\n",
      "43147/43147 [==============================] - 5s 114us/step - loss: 1.0598 - acc: 0.5593\n",
      "Epoch 52/100\n",
      "43147/43147 [==============================] - 5s 109us/step - loss: 1.0581 - acc: 0.5609\n",
      "Epoch 53/100\n",
      "43147/43147 [==============================] - 5s 109us/step - loss: 1.0576 - acc: 0.5601\n",
      "Epoch 54/100\n",
      "43147/43147 [==============================] - 5s 106us/step - loss: 1.0589 - acc: 0.5610\n",
      "Epoch 55/100\n",
      "43147/43147 [==============================] - 5s 106us/step - loss: 1.0582 - acc: 0.5603 1s - lo\n",
      "Epoch 56/100\n",
      "43147/43147 [==============================] - 5s 105us/step - loss: 1.0564 - acc: 0.5615\n",
      "Epoch 57/100\n",
      "43147/43147 [==============================] - 5s 106us/step - loss: 1.0571 - acc: 0.5609 0s - loss: 1.0570 \n",
      "Epoch 58/100\n",
      "43147/43147 [==============================] - 5s 105us/step - loss: 1.0570 - acc: 0.5619\n",
      "Epoch 59/100\n",
      "43147/43147 [==============================] - 5s 106us/step - loss: 1.0564 - acc: 0.5622\n",
      "Epoch 60/100\n",
      "43147/43147 [==============================] - 5s 106us/step - loss: 1.0568 - acc: 0.5626 4s - loss - ETA: 2s - loss: \n",
      "Epoch 61/100\n",
      "43147/43147 [==============================] - 5s 106us/step - loss: 1.0562 - acc: 0.5621\n",
      "Epoch 62/100\n",
      "43147/43147 [==============================] - 5s 110us/step - loss: 1.0562 - acc: 0.5622\n",
      "Epoch 63/100\n",
      "43147/43147 [==============================] - 5s 112us/step - loss: 1.0555 - acc: 0.5623\n",
      "Epoch 64/100\n",
      "43147/43147 [==============================] - 5s 105us/step - loss: 1.0553 - acc: 0.5615\n",
      "Epoch 65/100\n",
      "43147/43147 [==============================] - 5s 105us/step - loss: 1.0545 - acc: 0.5625\n",
      "Epoch 66/100\n",
      "43147/43147 [==============================] - 5s 105us/step - loss: 1.0541 - acc: 0.5628\n",
      "Epoch 67/100\n",
      "43147/43147 [==============================] - 5s 105us/step - loss: 1.0535 - acc: 0.5628\n",
      "Epoch 68/100\n",
      "43147/43147 [==============================] - 5s 105us/step - loss: 1.0548 - acc: 0.5619\n",
      "Epoch 69/100\n",
      "43147/43147 [==============================] - 5s 110us/step - loss: 1.0530 - acc: 0.5623\n",
      "Epoch 70/100\n",
      "43147/43147 [==============================] - 5s 106us/step - loss: 1.0528 - acc: 0.5634\n",
      "Epoch 71/100\n",
      "43147/43147 [==============================] - 5s 105us/step - loss: 1.0523 - acc: 0.5631\n",
      "Epoch 72/100\n",
      "43147/43147 [==============================] - 5s 106us/step - loss: 1.0520 - acc: 0.5642\n",
      "Epoch 73/100\n",
      "43147/43147 [==============================] - 5s 105us/step - loss: 1.0520 - acc: 0.5621\n",
      "Epoch 74/100\n",
      "43147/43147 [==============================] - 5s 105us/step - loss: 1.0510 - acc: 0.5624\n",
      "Epoch 75/100\n",
      "43147/43147 [==============================] - 4s 94us/step - loss: 1.0523 - acc: 0.5639\n",
      "Epoch 76/100\n",
      "43147/43147 [==============================] - 4s 92us/step - loss: 1.0510 - acc: 0.5651\n",
      "Epoch 77/100\n",
      "43147/43147 [==============================] - 5s 116us/step - loss: 1.0502 - acc: 0.5632\n",
      "Epoch 78/100\n",
      "43147/43147 [==============================] - 5s 108us/step - loss: 1.0506 - acc: 0.5642\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43147/43147 [==============================] - 5s 107us/step - loss: 1.0512 - acc: 0.5649\n",
      "Epoch 80/100\n",
      "43147/43147 [==============================] - 5s 107us/step - loss: 1.0496 - acc: 0.5646\n",
      "Epoch 81/100\n",
      "43147/43147 [==============================] - 5s 109us/step - loss: 1.0488 - acc: 0.5659\n",
      "Epoch 82/100\n",
      "43147/43147 [==============================] - 5s 108us/step - loss: 1.0488 - acc: 0.5667\n",
      "Epoch 83/100\n",
      "43147/43147 [==============================] - 5s 107us/step - loss: 1.0501 - acc: 0.5641\n",
      "Epoch 84/100\n",
      "43147/43147 [==============================] - 5s 107us/step - loss: 1.0482 - acc: 0.5643 0s - loss: 1.0466 - \n",
      "Epoch 85/100\n",
      "43147/43147 [==============================] - 5s 106us/step - loss: 1.0475 - acc: 0.5669\n",
      "Epoch 86/100\n",
      "43147/43147 [==============================] - 5s 107us/step - loss: 1.0482 - acc: 0.5652\n",
      "Epoch 87/100\n",
      "43147/43147 [==============================] - 5s 107us/step - loss: 1.0474 - acc: 0.5656\n",
      "Epoch 88/100\n",
      "43147/43147 [==============================] - 5s 107us/step - loss: 1.0477 - acc: 0.5664\n",
      "Epoch 89/100\n",
      "43147/43147 [==============================] - 5s 109us/step - loss: 1.0475 - acc: 0.5676 2s - loss: - E\n",
      "Epoch 90/100\n",
      "43147/43147 [==============================] - 5s 108us/step - loss: 1.0467 - acc: 0.5667 0s - loss: 1.0471 - acc\n",
      "Epoch 91/100\n",
      "43147/43147 [==============================] - 5s 116us/step - loss: 1.0483 - acc: 0.5648\n",
      "Epoch 92/100\n",
      "43147/43147 [==============================] - 5s 112us/step - loss: 1.0467 - acc: 0.5653\n",
      "Epoch 93/100\n",
      "43147/43147 [==============================] - 5s 107us/step - loss: 1.0472 - acc: 0.5657\n",
      "Epoch 94/100\n",
      "43147/43147 [==============================] - 5s 106us/step - loss: 1.0460 - acc: 0.5678 0s - loss: 1.046\n",
      "Epoch 95/100\n",
      "43147/43147 [==============================] - 5s 107us/step - loss: 1.0450 - acc: 0.5679\n",
      "Epoch 96/100\n",
      "43147/43147 [==============================] - 5s 107us/step - loss: 1.0457 - acc: 0.5669\n",
      "Epoch 97/100\n",
      "43147/43147 [==============================] - 5s 106us/step - loss: 1.0453 - acc: 0.5666\n",
      "Epoch 98/100\n",
      "43147/43147 [==============================] - 5s 107us/step - loss: 1.0455 - acc: 0.5659\n",
      "Epoch 99/100\n",
      "43147/43147 [==============================] - 5s 107us/step - loss: 1.0439 - acc: 0.5667\n",
      "Epoch 100/100\n",
      "43147/43147 [==============================] - 5s 107us/step - loss: 1.0448 - acc: 0.5661\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train.values, y_train.values, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.83      0.70     17206\n",
      "           2       0.51      0.56      0.53     11049\n",
      "           3       0.47      0.27      0.34      9722\n",
      "           4       0.79      0.27      0.40      3912\n",
      "           5       0.80      0.53      0.64      1258\n",
      "\n",
      "    accuracy                           0.57     43147\n",
      "   macro avg       0.64      0.49      0.52     43147\n",
      "weighted avg       0.57      0.57      0.55     43147\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = model.predict_classes(X_train.values)\n",
    "print(metrics.classification_report(y_train,scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scores are minutely higher than the last model but it also is a lot slower. We should see if taking away some nodes helps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BuildModel(5, 18) #half as many nodes in each hidden layer\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "43147/43147 [==============================] - 7s 151us/step - loss: 1.3193 - acc: 0.4496\n",
      "Epoch 2/100\n",
      "43147/43147 [==============================] - 4s 98us/step - loss: 1.2472 - acc: 0.4838\n",
      "Epoch 3/100\n",
      "43147/43147 [==============================] - 4s 98us/step - loss: 1.2150 - acc: 0.5028\n",
      "Epoch 4/100\n",
      "43147/43147 [==============================] - 4s 98us/step - loss: 1.1942 - acc: 0.5133\n",
      "Epoch 5/100\n",
      "43147/43147 [==============================] - 4s 101us/step - loss: 1.1782 - acc: 0.5194 0s - loss: 1.1785 - acc:\n",
      "Epoch 6/100\n",
      "43147/43147 [==============================] - 5s 105us/step - loss: 1.1659 - acc: 0.5226 1s - loss:\n",
      "Epoch 7/100\n",
      "43147/43147 [==============================] - 4s 96us/step - loss: 1.1558 - acc: 0.5268\n",
      "Epoch 8/100\n",
      "43147/43147 [==============================] - 4s 97us/step - loss: 1.1478 - acc: 0.5265: 0s - loss: 1.1483 - \n",
      "Epoch 9/100\n",
      "43147/43147 [==============================] - 4s 97us/step - loss: 1.1409 - acc: 0.5274: 0s - loss: 1.1414 - acc\n",
      "Epoch 10/100\n",
      "43147/43147 [==============================] - 4s 97us/step - loss: 1.1349 - acc: 0.5299\n",
      "Epoch 11/100\n",
      "43147/43147 [==============================] - 4s 98us/step - loss: 1.1310 - acc: 0.5301\n",
      "Epoch 12/100\n",
      "43147/43147 [==============================] - 4s 101us/step - loss: 1.1275 - acc: 0.5343 0s - loss: 1.1278 - acc:\n",
      "Epoch 13/100\n",
      "43147/43147 [==============================] - 4s 101us/step - loss: 1.1258 - acc: 0.5336\n",
      "Epoch 14/100\n",
      "43147/43147 [==============================] - 4s 99us/step - loss: 1.1231 - acc: 0.5361\n",
      "Epoch 15/100\n",
      "43147/43147 [==============================] - 4s 99us/step - loss: 1.1205 - acc: 0.5352\n",
      "Epoch 16/100\n",
      "43147/43147 [==============================] - 4s 97us/step - loss: 1.1194 - acc: 0.5360\n",
      "Epoch 17/100\n",
      "43147/43147 [==============================] - 4s 96us/step - loss: 1.1166 - acc: 0.5368: 0s - loss: 1\n",
      "Epoch 18/100\n",
      "43147/43147 [==============================] - 4s 97us/step - loss: 1.1159 - acc: 0.5372\n",
      "Epoch 19/100\n",
      "43147/43147 [==============================] - 4s 100us/step - loss: 1.1141 - acc: 0.5385 0s - loss: 1.\n",
      "Epoch 20/100\n",
      "43147/43147 [==============================] - 4s 99us/step - loss: 1.1126 - acc: 0.5370\n",
      "Epoch 21/100\n",
      "43147/43147 [==============================] - 5s 107us/step - loss: 1.1104 - acc: 0.5386\n",
      "Epoch 22/100\n",
      "43147/43147 [==============================] - 4s 102us/step - loss: 1.1092 - acc: 0.5387\n",
      "Epoch 23/100\n",
      "43147/43147 [==============================] - 4s 97us/step - loss: 1.1084 - acc: 0.5375\n",
      "Epoch 24/100\n",
      "43147/43147 [==============================] - 4s 95us/step - loss: 1.1064 - acc: 0.5394\n",
      "Epoch 25/100\n",
      "43147/43147 [==============================] - 4s 98us/step - loss: 1.1064 - acc: 0.5403\n",
      "Epoch 26/100\n",
      "43147/43147 [==============================] - 4s 96us/step - loss: 1.1046 - acc: 0.5395\n",
      "Epoch 27/100\n",
      "43147/43147 [==============================] - 3s 79us/step - loss: 1.1040 - acc: 0.5425\n",
      "Epoch 28/100\n",
      "43147/43147 [==============================] - 4s 95us/step - loss: 1.1027 - acc: 0.5413\n",
      "Epoch 29/100\n",
      "43147/43147 [==============================] - 4s 98us/step - loss: 1.1026 - acc: 0.5418\n",
      "Epoch 30/100\n",
      "43147/43147 [==============================] - 4s 97us/step - loss: 1.1010 - acc: 0.5412\n",
      "Epoch 31/100\n",
      "43147/43147 [==============================] - 4s 97us/step - loss: 1.1002 - acc: 0.5413\n",
      "Epoch 32/100\n",
      "43147/43147 [==============================] - 4s 97us/step - loss: 1.0996 - acc: 0.5426\n",
      "Epoch 33/100\n",
      "43147/43147 [==============================] - 4s 97us/step - loss: 1.0996 - acc: 0.5427\n",
      "Epoch 34/100\n",
      "43147/43147 [==============================] - 4s 96us/step - loss: 1.0985 - acc: 0.5452\n",
      "Epoch 35/100\n",
      "43147/43147 [==============================] - 4s 95us/step - loss: 1.0977 - acc: 0.5444\n",
      "Epoch 36/100\n",
      "43147/43147 [==============================] - 4s 97us/step - loss: 1.0972 - acc: 0.5439\n",
      "Epoch 37/100\n",
      "43147/43147 [==============================] - 5s 112us/step - loss: 1.0953 - acc: 0.5446\n",
      "Epoch 38/100\n",
      "43147/43147 [==============================] - 4s 98us/step - loss: 1.0960 - acc: 0.5449\n",
      "Epoch 39/100\n",
      "43147/43147 [==============================] - 4s 97us/step - loss: 1.0953 - acc: 0.5441: 0s - loss: 1.0962 \n",
      "Epoch 40/100\n",
      "43147/43147 [==============================] - 4s 97us/step - loss: 1.0947 - acc: 0.5470: 1s - \n",
      "Epoch 41/100\n",
      "43147/43147 [==============================] - 4s 96us/step - loss: 1.0935 - acc: 0.5450\n",
      "Epoch 42/100\n",
      "43147/43147 [==============================] - 4s 97us/step - loss: 1.0938 - acc: 0.5454\n",
      "Epoch 43/100\n",
      "43147/43147 [==============================] - 4s 96us/step - loss: 1.0932 - acc: 0.5454\n",
      "Epoch 44/100\n",
      "43147/43147 [==============================] - 4s 96us/step - loss: 1.0928 - acc: 0.5467: 0s - loss: 1.0927 - acc: \n",
      "Epoch 45/100\n",
      "43147/43147 [==============================] - 4s 97us/step - loss: 1.0921 - acc: 0.5462\n",
      "Epoch 46/100\n",
      "43147/43147 [==============================] - 4s 97us/step - loss: 1.0923 - acc: 0.5485: 0s - loss: 1.0906 -\n",
      "Epoch 47/100\n",
      "43147/43147 [==============================] - 4s 96us/step - loss: 1.0908 - acc: 0.5467\n",
      "Epoch 48/100\n",
      "43147/43147 [==============================] - 4s 96us/step - loss: 1.0904 - acc: 0.5467\n",
      "Epoch 49/100\n",
      "43147/43147 [==============================] - 4s 96us/step - loss: 1.0893 - acc: 0.5491\n",
      "Epoch 50/100\n",
      "43147/43147 [==============================] - 4s 97us/step - loss: 1.0884 - acc: 0.5480 ETA: 2s - loss - ETA: 1s - los\n",
      "Epoch 51/100\n",
      "43147/43147 [==============================] - 4s 97us/step - loss: 1.0891 - acc: 0.5462\n",
      "Epoch 52/100\n",
      "43147/43147 [==============================] - 4s 102us/step - loss: 1.0881 - acc: 0.5468\n",
      "Epoch 53/100\n",
      "43147/43147 [==============================] - 4s 102us/step - loss: 1.0880 - acc: 0.5480\n",
      "Epoch 54/100\n",
      "43147/43147 [==============================] - 4s 94us/step - loss: 1.0881 - acc: 0.5466\n",
      "Epoch 55/100\n",
      "43147/43147 [==============================] - 4s 95us/step - loss: 1.0867 - acc: 0.5484\n",
      "Epoch 56/100\n",
      "43147/43147 [==============================] - 4s 95us/step - loss: 1.0863 - acc: 0.5476: 1s - loss: 1.0819  - ETA: 0s - loss: 1.08\n",
      "Epoch 57/100\n",
      "43147/43147 [==============================] - 4s 96us/step - loss: 1.0856 - acc: 0.5493\n",
      "Epoch 58/100\n",
      "43147/43147 [==============================] - 4s 97us/step - loss: 1.0862 - acc: 0.5483\n",
      "Epoch 59/100\n",
      "43147/43147 [==============================] - 4s 98us/step - loss: 1.0861 - acc: 0.5479: 1s \n",
      "Epoch 60/100\n",
      "43147/43147 [==============================] - 4s 99us/step - loss: 1.0852 - acc: 0.5483: 1s\n",
      "Epoch 61/100\n",
      "43147/43147 [==============================] - 4s 96us/step - loss: 1.0849 - acc: 0.5488: 0s - loss: 1.0838 - a\n",
      "Epoch 62/100\n",
      "43147/43147 [==============================] - 4s 96us/step - loss: 1.0833 - acc: 0.5492\n",
      "Epoch 63/100\n",
      "43147/43147 [==============================] - 4s 94us/step - loss: 1.0836 - acc: 0.5471\n",
      "Epoch 64/100\n",
      "43147/43147 [==============================] - 4s 93us/step - loss: 1.0837 - acc: 0.5491\n",
      "Epoch 65/100\n",
      "43147/43147 [==============================] - 4s 93us/step - loss: 1.0840 - acc: 0.5500\n",
      "Epoch 66/100\n",
      "43147/43147 [==============================] - 4s 93us/step - loss: 1.0834 - acc: 0.5489\n",
      "Epoch 67/100\n",
      "43147/43147 [==============================] - 4s 93us/step - loss: 1.0820 - acc: 0.5507\n",
      "Epoch 68/100\n",
      "43147/43147 [==============================] - 4s 103us/step - loss: 1.0823 - acc: 0.5501\n",
      "Epoch 69/100\n",
      "43147/43147 [==============================] - 4s 97us/step - loss: 1.0827 - acc: 0.5488\n",
      "Epoch 70/100\n",
      "43147/43147 [==============================] - 4s 95us/step - loss: 1.0814 - acc: 0.5504\n",
      "Epoch 71/100\n",
      "43147/43147 [==============================] - 4s 93us/step - loss: 1.0819 - acc: 0.5513: 0s - loss: 1.0815 - acc: \n",
      "Epoch 72/100\n",
      "43147/43147 [==============================] - 4s 92us/step - loss: 1.0813 - acc: 0.5486\n",
      "Epoch 73/100\n",
      "43147/43147 [==============================] - 4s 90us/step - loss: 1.0814 - acc: 0.5495\n",
      "Epoch 74/100\n",
      "43147/43147 [==============================] - 4s 96us/step - loss: 1.0812 - acc: 0.5496\n",
      "Epoch 75/100\n",
      "43147/43147 [==============================] - 4s 96us/step - loss: 1.0806 - acc: 0.5499\n",
      "Epoch 76/100\n",
      "43147/43147 [==============================] - 4s 97us/step - loss: 1.0805 - acc: 0.5483ETA: 1s\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43147/43147 [==============================] - 4s 96us/step - loss: 1.0797 - acc: 0.5499: 1s - loss: 1.0713 - acc: 0.553 - ETA: 1s - \n",
      "Epoch 78/100\n",
      "43147/43147 [==============================] - 5s 106us/step - loss: 1.0795 - acc: 0.5494\n",
      "Epoch 79/100\n",
      "43147/43147 [==============================] - 4s 95us/step - loss: 1.0790 - acc: 0.5513\n",
      "Epoch 80/100\n",
      "43147/43147 [==============================] - 5s 113us/step - loss: 1.0795 - acc: 0.5514 0s - loss: 1.0781 - \n",
      "Epoch 81/100\n",
      "43147/43147 [==============================] - 4s 96us/step - loss: 1.0779 - acc: 0.5512: 0s - loss: 1.0770 - acc: \n",
      "Epoch 82/100\n",
      "43147/43147 [==============================] - 4s 97us/step - loss: 1.0786 - acc: 0.5510\n",
      "Epoch 83/100\n",
      "43147/43147 [==============================] - 4s 94us/step - loss: 1.0781 - acc: 0.5519: \n",
      "Epoch 84/100\n",
      "43147/43147 [==============================] - 5s 112us/step - loss: 1.0784 - acc: 0.5501 0s - loss: 1.0\n",
      "Epoch 85/100\n",
      "43147/43147 [==============================] - 4s 94us/step - loss: 1.0772 - acc: 0.5521\n",
      "Epoch 86/100\n",
      "43147/43147 [==============================] - 4s 95us/step - loss: 1.0777 - acc: 0.5515\n",
      "Epoch 87/100\n",
      "43147/43147 [==============================] - 4s 94us/step - loss: 1.0784 - acc: 0.5523\n",
      "Epoch 88/100\n",
      "43147/43147 [==============================] - 4s 99us/step - loss: 1.0771 - acc: 0.5510\n",
      "Epoch 89/100\n",
      "43147/43147 [==============================] - 4s 95us/step - loss: 1.0759 - acc: 0.5533: \n",
      "Epoch 90/100\n",
      "43147/43147 [==============================] - 4s 96us/step - loss: 1.0748 - acc: 0.5545\n",
      "Epoch 91/100\n",
      "43147/43147 [==============================] - 4s 97us/step - loss: 1.0765 - acc: 0.5515\n",
      "Epoch 92/100\n",
      "43147/43147 [==============================] - 4s 96us/step - loss: 1.0757 - acc: 0.5535\n",
      "Epoch 93/100\n",
      "43147/43147 [==============================] - 4s 104us/step - loss: 1.0760 - acc: 0.5527\n",
      "Epoch 94/100\n",
      "43147/43147 [==============================] - 4s 97us/step - loss: 1.0753 - acc: 0.5535\n",
      "Epoch 95/100\n",
      "43147/43147 [==============================] - 4s 90us/step - loss: 1.0752 - acc: 0.5527\n",
      "Epoch 96/100\n",
      "43147/43147 [==============================] - 4s 94us/step - loss: 1.0750 - acc: 0.5539: 1s - loss:\n",
      "Epoch 97/100\n",
      "43147/43147 [==============================] - 5s 112us/step - loss: 1.0745 - acc: 0.5520\n",
      "Epoch 98/100\n",
      "43147/43147 [==============================] - 4s 95us/step - loss: 1.0740 - acc: 0.5537: 0s - loss: 1.0732 - acc: \n",
      "Epoch 99/100\n",
      "43147/43147 [==============================] - ETA: 0s - loss: 1.0745 - acc: 0.5531- ETA: - ETA: 0s - loss: - ETA: 0s - loss: 1.0732 - acc: 0. - 5s 115us/step - loss: 1.0745 - acc: 0.5534\n",
      "Epoch 100/100\n",
      "43147/43147 [==============================] - 5s 107us/step - loss: 1.0736 - acc: 0.5539\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train.values, y_train.values, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.88      0.69     17206\n",
      "           2       0.53      0.49      0.51     11049\n",
      "           3       0.47      0.19      0.27      9722\n",
      "           4       0.74      0.27      0.39      3912\n",
      "           5       0.85      0.48      0.61      1258\n",
      "\n",
      "    accuracy                           0.56     43147\n",
      "   macro avg       0.63      0.46      0.49     43147\n",
      "weighted avg       0.56      0.56      0.52     43147\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = model.predict_classes(X_train.values)\n",
    "print(metrics.classification_report(y_train,scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our f1 scores are a few percentage points lower but I think this is the best version for number of nodes and layers because thi is faster than the previous and the difference is small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aside from layers, there are also other parameters we should try to optimize. Ideally, we would have a higher learning rate so that we could train the model faster. Let's try to find the best reasonble values for these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search will be too slow as it takes around 5 minutes to do 100 epochs on my computer so we will construct a few with different values.Let's start with e-3 and go up and down by factors of 10 as we would with an encompassing grid search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BuildModel(5, 18) #half as many nodes in each hidden layer\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=keras.optimizers.SGD(lr=1e-3), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "43147/43147 [==============================] - 7s 165us/step - loss: 1.4912 - acc: 0.3992 0s - loss: 1.4985 - acc\n",
      "Epoch 2/50\n",
      "43147/43147 [==============================] - 4s 98us/step - loss: 1.3684 - acc: 0.4131\n",
      "Epoch 3/50\n",
      "43147/43147 [==============================] - 4s 82us/step - loss: 1.3324 - acc: 0.4315\n",
      "Epoch 4/50\n",
      "43147/43147 [==============================] - 4s 92us/step - loss: 1.3152 - acc: 0.4439: 0s - loss: 1.3150 - ac\n",
      "Epoch 5/50\n",
      "43147/43147 [==============================] - 4s 98us/step - loss: 1.3043 - acc: 0.4500\n",
      "Epoch 6/50\n",
      "43147/43147 [==============================] - 4s 99us/step - loss: 1.2959 - acc: 0.4563\n",
      "Epoch 7/50\n",
      "43147/43147 [==============================] - 4s 98us/step - loss: 1.2891 - acc: 0.4607\n",
      "Epoch 8/50\n",
      "43147/43147 [==============================] - 4s 98us/step - loss: 1.2834 - acc: 0.4627\n",
      "Epoch 9/50\n",
      "43147/43147 [==============================] - 4s 102us/step - loss: 1.2786 - acc: 0.4644\n",
      "Epoch 10/50\n",
      "43147/43147 [==============================] - 5s 112us/step - loss: 1.2744 - acc: 0.4652 1s - lo\n",
      "Epoch 11/50\n",
      "43147/43147 [==============================] - 4s 100us/step - loss: 1.2705 - acc: 0.4659\n",
      "Epoch 12/50\n",
      "43147/43147 [==============================] - 4s 99us/step - loss: 1.2671 - acc: 0.4669\n",
      "Epoch 13/50\n",
      "43147/43147 [==============================] - 4s 99us/step - loss: 1.2640 - acc: 0.4684\n",
      "Epoch 14/50\n",
      "43147/43147 [==============================] - 4s 99us/step - loss: 1.2607 - acc: 0.4689\n",
      "Epoch 15/50\n",
      "43147/43147 [==============================] - 4s 98us/step - loss: 1.2576 - acc: 0.4696\n",
      "Epoch 16/50\n",
      "43147/43147 [==============================] - 4s 99us/step - loss: 1.2544 - acc: 0.4711\n",
      "Epoch 17/50\n",
      "43147/43147 [==============================] - 4s 98us/step - loss: 1.2508 - acc: 0.4733\n",
      "Epoch 18/50\n",
      "43147/43147 [==============================] - 4s 99us/step - loss: 1.2473 - acc: 0.4752\n",
      "Epoch 19/50\n",
      "43147/43147 [==============================] - 4s 100us/step - loss: 1.2436 - acc: 0.4777\n",
      "Epoch 20/50\n",
      "43147/43147 [==============================] - 4s 99us/step - loss: 1.2403 - acc: 0.4800\n",
      "Epoch 21/50\n",
      "43147/43147 [==============================] - 4s 100us/step - loss: 1.2370 - acc: 0.4836\n",
      "Epoch 22/50\n",
      "43147/43147 [==============================] - 4s 98us/step - loss: 1.2337 - acc: 0.4861\n",
      "Epoch 23/50\n",
      "43147/43147 [==============================] - 4s 100us/step - loss: 1.2305 - acc: 0.4885\n",
      "Epoch 24/50\n",
      "43147/43147 [==============================] - 4s 98us/step - loss: 1.2275 - acc: 0.4900\n",
      "Epoch 25/50\n",
      "43147/43147 [==============================] - 5s 113us/step - loss: 1.2250 - acc: 0.4922\n",
      "Epoch 26/50\n",
      "43147/43147 [==============================] - 4s 100us/step - loss: 1.2226 - acc: 0.4944 0s - loss: 1\n",
      "Epoch 27/50\n",
      "43147/43147 [==============================] - 4s 99us/step - loss: 1.2202 - acc: 0.4960\n",
      "Epoch 28/50\n",
      "43147/43147 [==============================] - 4s 100us/step - loss: 1.2179 - acc: 0.4989\n",
      "Epoch 29/50\n",
      "43147/43147 [==============================] - 4s 98us/step - loss: 1.2160 - acc: 0.5010\n",
      "Epoch 30/50\n",
      "43147/43147 [==============================] - 4s 98us/step - loss: 1.2141 - acc: 0.5037: 0s - loss: 1.2148 - acc: 0.\n",
      "Epoch 31/50\n",
      "43147/43147 [==============================] - 4s 99us/step - loss: 1.2125 - acc: 0.5060\n",
      "Epoch 32/50\n",
      "43147/43147 [==============================] - 4s 99us/step - loss: 1.2108 - acc: 0.5070\n",
      "Epoch 33/50\n",
      "43147/43147 [==============================] - 4s 99us/step - loss: 1.2093 - acc: 0.5084\n",
      "Epoch 34/50\n",
      "43147/43147 [==============================] - 4s 98us/step - loss: 1.2080 - acc: 0.5086\n",
      "Epoch 35/50\n",
      "43147/43147 [==============================] - 4s 98us/step - loss: 1.2066 - acc: 0.5107\n",
      "Epoch 36/50\n",
      "43147/43147 [==============================] - 4s 98us/step - loss: 1.2054 - acc: 0.5103: 1\n",
      "Epoch 37/50\n",
      "43147/43147 [==============================] - 4s 98us/step - loss: 1.2043 - acc: 0.5126\n",
      "Epoch 38/50\n",
      "43147/43147 [==============================] - 4s 99us/step - loss: 1.2029 - acc: 0.5124\n",
      "Epoch 39/50\n",
      "43147/43147 [==============================] - 4s 98us/step - loss: 1.2020 - acc: 0.5138\n",
      "Epoch 40/50\n",
      "43147/43147 [==============================] - 5s 110us/step - loss: 1.2008 - acc: 0.5146\n",
      "Epoch 41/50\n",
      "43147/43147 [==============================] - 4s 103us/step - loss: 1.2000 - acc: 0.5153\n",
      "Epoch 42/50\n",
      "43147/43147 [==============================] - 4s 98us/step - loss: 1.1988 - acc: 0.5159\n",
      "Epoch 43/50\n",
      "43147/43147 [==============================] - 4s 99us/step - loss: 1.1975 - acc: 0.5170\n",
      "Epoch 44/50\n",
      "43147/43147 [==============================] - 4s 97us/step - loss: 1.1968 - acc: 0.5172\n",
      "Epoch 45/50\n",
      "43147/43147 [==============================] - ETA: 0s - loss: 1.1961 - acc: 0.517 - 4s 83us/step - loss: 1.1957 - acc: 0.5175\n",
      "Epoch 46/50\n",
      "43147/43147 [==============================] - 4s 92us/step - loss: 1.1945 - acc: 0.5179\n",
      "Epoch 47/50\n",
      "43147/43147 [==============================] - 4s 100us/step - loss: 1.1933 - acc: 0.5185\n",
      "Epoch 48/50\n",
      "43147/43147 [==============================] - 4s 99us/step - loss: 1.1923 - acc: 0.5198: \n",
      "Epoch 49/50\n",
      "43147/43147 [==============================] - 4s 98us/step - loss: 1.1917 - acc: 0.5202\n",
      "Epoch 50/50\n",
      "43147/43147 [==============================] - 4s 99us/step - loss: 1.1903 - acc: 0.5212\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train.values, y_train.values, epochs = 50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.78      0.67     17206\n",
      "           2       0.47      0.53      0.50     11049\n",
      "           3       0.38      0.19      0.25      9722\n",
      "           4       0.42      0.24      0.30      3912\n",
      "           5       0.60      0.38      0.47      1258\n",
      "\n",
      "    accuracy                           0.52     43147\n",
      "   macro avg       0.49      0.42      0.44     43147\n",
      "weighted avg       0.50      0.52      0.49     43147\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = model.predict_classes(X_train.values)\n",
    "print(metrics.classification_report(y_train,scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This value seems to have lowered our accuracy. Let's try a lower learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BuildModel(5, 18) #half as many nodes in each hidden layer\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=keras.optimizers.SGD(lr=1e-4), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "43147/43147 [==============================] - 7s 152us/step - loss: 1.8323 - acc: 0.0752\n",
      "Epoch 2/50\n",
      "43147/43147 [==============================] - 4s 99us/step - loss: 1.7201 - acc: 0.3975\n",
      "Epoch 3/50\n",
      "43147/43147 [==============================] - 4s 99us/step - loss: 1.6526 - acc: 0.3988\n",
      "Epoch 4/50\n",
      "43147/43147 [==============================] - 4s 99us/step - loss: 1.6040 - acc: 0.3988\n",
      "Epoch 5/50\n",
      "43147/43147 [==============================] - 4s 101us/step - loss: 1.5659 - acc: 0.3988\n",
      "Epoch 6/50\n",
      "43147/43147 [==============================] - 4s 102us/step - loss: 1.5355 - acc: 0.3988\n",
      "Epoch 7/50\n",
      "43147/43147 [==============================] - 4s 101us/step - loss: 1.5102 - acc: 0.3988\n",
      "Epoch 8/50\n",
      "43147/43147 [==============================] - 4s 100us/step - loss: 1.4885 - acc: 0.3988\n",
      "Epoch 9/50\n",
      "43147/43147 [==============================] - 5s 106us/step - loss: 1.4695 - acc: 0.3988 0s - loss: 1\n",
      "Epoch 10/50\n",
      "43147/43147 [==============================] - 4s 100us/step - loss: 1.4529 - acc: 0.3988\n",
      "Epoch 11/50\n",
      "43147/43147 [==============================] - 5s 115us/step - loss: 1.4384 - acc: 0.3988 \n",
      "Epoch 12/50\n",
      "43147/43147 [==============================] - 5s 115us/step - loss: 1.4258 - acc: 0.3988\n",
      "Epoch 13/50\n",
      "43147/43147 [==============================] - 5s 117us/step - loss: 1.4150 - acc: 0.3988\n",
      "Epoch 14/50\n",
      "43147/43147 [==============================] - 4s 96us/step - loss: 1.4056 - acc: 0.3990\n",
      "Epoch 15/50\n",
      "43147/43147 [==============================] - 4s 98us/step - loss: 1.3975 - acc: 0.3991\n",
      "Epoch 16/50\n",
      "43147/43147 [==============================] - 4s 97us/step - loss: 1.3903 - acc: 0.4004: 0s - loss: 1.3902 \n",
      "Epoch 17/50\n",
      "43147/43147 [==============================] - 4s 103us/step - loss: 1.3839 - acc: 0.4040\n",
      "Epoch 18/50\n",
      "43147/43147 [==============================] - 4s 96us/step - loss: 1.3781 - acc: 0.4073\n",
      "Epoch 19/50\n",
      "43147/43147 [==============================] - 4s 104us/step - loss: 1.3729 - acc: 0.4112TA: 0s - loss: 1.3728 \n",
      "Epoch 20/50\n",
      "43147/43147 [==============================] - 4s 100us/step - loss: 1.3681 - acc: 0.4130\n",
      "Epoch 21/50\n",
      "43147/43147 [==============================] - 4s 99us/step - loss: 1.3637 - acc: 0.4163\n",
      "Epoch 22/50\n",
      "43147/43147 [==============================] - 4s 100us/step - loss: 1.3597 - acc: 0.4192\n",
      "Epoch 23/50\n",
      "43147/43147 [==============================] - 4s 100us/step - loss: 1.3560 - acc: 0.4222\n",
      "Epoch 24/50\n",
      "43147/43147 [==============================] - 4s 100us/step - loss: 1.3525 - acc: 0.4253 \n",
      "Epoch 25/50\n",
      "43147/43147 [==============================] - 4s 100us/step - loss: 1.3493 - acc: 0.4274\n",
      "Epoch 26/50\n",
      "43147/43147 [==============================] - 5s 110us/step - loss: 1.3464 - acc: 0.4309\n",
      "Epoch 27/50\n",
      "43147/43147 [==============================] - 4s 104us/step - loss: 1.3437 - acc: 0.4323\n",
      "Epoch 28/50\n",
      "43147/43147 [==============================] - 4s 100us/step - loss: 1.3411 - acc: 0.4343\n",
      "Epoch 29/50\n",
      "43147/43147 [==============================] - 4s 100us/step - loss: 1.3387 - acc: 0.4365\n",
      "Epoch 30/50\n",
      "43147/43147 [==============================] - 4s 100us/step - loss: 1.3365 - acc: 0.4376\n",
      "Epoch 31/50\n",
      "43147/43147 [==============================] - 4s 98us/step - loss: 1.3344 - acc: 0.4412\n",
      "Epoch 32/50\n",
      "43147/43147 [==============================] - 4s 99us/step - loss: 1.3324 - acc: 0.4417\n",
      "Epoch 33/50\n",
      "43147/43147 [==============================] - 4s 101us/step - loss: 1.3305 - acc: 0.4445\n",
      "Epoch 34/50\n",
      "43147/43147 [==============================] - 4s 100us/step - loss: 1.3286 - acc: 0.4461\n",
      "Epoch 35/50\n",
      "43147/43147 [==============================] - 4s 101us/step - loss: 1.3269 - acc: 0.4470\n",
      "Epoch 36/50\n",
      "43147/43147 [==============================] - 4s 99us/step - loss: 1.3253 - acc: 0.4489\n",
      "Epoch 37/50\n",
      "43147/43147 [==============================] - 4s 99us/step - loss: 1.3237 - acc: 0.4512\n",
      "Epoch 38/50\n",
      "43147/43147 [==============================] - 4s 98us/step - loss: 1.3221 - acc: 0.4516\n",
      "Epoch 39/50\n",
      "43147/43147 [==============================] - 4s 100us/step - loss: 1.3206 - acc: 0.4538\n",
      "Epoch 40/50\n",
      "43147/43147 [==============================] - 4s 98us/step - loss: 1.3191 - acc: 0.4543\n",
      "Epoch 41/50\n",
      "43147/43147 [==============================] - 5s 107us/step - loss: 1.3177 - acc: 0.4552 0s - loss: 1.3172 - acc: \n",
      "Epoch 42/50\n",
      "43147/43147 [==============================] - 5s 106us/step - loss: 1.3163 - acc: 0.4573\n",
      "Epoch 43/50\n",
      "43147/43147 [==============================] - 4s 100us/step - loss: 1.3150 - acc: 0.4581\n",
      "Epoch 44/50\n",
      "43147/43147 [==============================] - 4s 103us/step - loss: 1.3137 - acc: 0.4590 2s - loss - \n",
      "Epoch 45/50\n",
      "43147/43147 [==============================] - 4s 99us/step - loss: 1.3124 - acc: 0.4598: 0s - loss: 1.\n",
      "Epoch 46/50\n",
      "43147/43147 [==============================] - 4s 101us/step - loss: 1.3111 - acc: 0.4607\n",
      "Epoch 47/50\n",
      "43147/43147 [==============================] - 4s 102us/step - loss: 1.3099 - acc: 0.4627\n",
      "Epoch 48/50\n",
      "43147/43147 [==============================] - 4s 101us/step - loss: 1.3087 - acc: 0.4635\n",
      "Epoch 49/50\n",
      "43147/43147 [==============================] - 4s 101us/step - loss: 1.3075 - acc: 0.4641\n",
      "Epoch 50/50\n",
      "43147/43147 [==============================] - 4s 101us/step - loss: 1.3064 - acc: 0.4651\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train.values, y_train.values, epochs = 50) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It makes sense that our accuracy score is lower with this as we need to raise the learning rate to get a more optimum convergence rate. Let's raise it to e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BuildModel(5, 18) #half as many nodes in each hidden layer\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=keras.optimizers.SGD(lr=1e-2), metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "43147/43147 [==============================] - 7s 171us/step - loss: 1.3481 - acc: 0.4110 2s -\n",
      "Epoch 2/50\n",
      "43147/43147 [==============================] - 4s 101us/step - loss: 1.2668 - acc: 0.4541\n",
      "Epoch 3/50\n",
      "43147/43147 [==============================] - 4s 97us/step - loss: 1.2354 - acc: 0.4754\n",
      "Epoch 4/50\n",
      "43147/43147 [==============================] - 4s 101us/step - loss: 1.2138 - acc: 0.4932\n",
      "Epoch 5/50\n",
      "43147/43147 [==============================] - 4s 101us/step - loss: 1.2005 - acc: 0.5012\n",
      "Epoch 6/50\n",
      "43147/43147 [==============================] - 4s 101us/step - loss: 1.1888 - acc: 0.5079 1s\n",
      "Epoch 7/50\n",
      "43147/43147 [==============================] - 5s 104us/step - loss: 1.1798 - acc: 0.5132\n",
      "Epoch 8/50\n",
      "43147/43147 [==============================] - 5s 110us/step - loss: 1.1701 - acc: 0.5165\n",
      "Epoch 9/50\n",
      "43147/43147 [==============================] - 5s 113us/step - loss: 1.1621 - acc: 0.5162\n",
      "Epoch 10/50\n",
      "43147/43147 [==============================] - 5s 119us/step - loss: 1.1560 - acc: 0.5211\n",
      "Epoch 11/50\n",
      "43147/43147 [==============================] - 4s 100us/step - loss: 1.1498 - acc: 0.5214\n",
      "Epoch 12/50\n",
      "43147/43147 [==============================] - 4s 101us/step - loss: 1.1450 - acc: 0.5232\n",
      "Epoch 13/50\n",
      "43147/43147 [==============================] - 4s 104us/step - loss: 1.1405 - acc: 0.5249\n",
      "Epoch 14/50\n",
      "43147/43147 [==============================] - 5s 109us/step - loss: 1.1354 - acc: 0.5278\n",
      "Epoch 15/50\n",
      "43147/43147 [==============================] - 5s 119us/step - loss: 1.1325 - acc: 0.5307 1s - loss: 1\n",
      "Epoch 16/50\n",
      "43147/43147 [==============================] - 5s 107us/step - loss: 1.1273 - acc: 0.5307\n",
      "Epoch 17/50\n",
      "43147/43147 [==============================] - 4s 101us/step - loss: 1.1236 - acc: 0.5345\n",
      "Epoch 18/50\n",
      "43147/43147 [==============================] - 4s 101us/step - loss: 1.1213 - acc: 0.5342 0s - loss: 1.1217 - acc: 0.\n",
      "Epoch 19/50\n",
      "43147/43147 [==============================] - 4s 101us/step - loss: 1.1184 - acc: 0.5342\n",
      "Epoch 20/50\n",
      "43147/43147 [==============================] - 4s 101us/step - loss: 1.1159 - acc: 0.5370\n",
      "Epoch 21/50\n",
      "43147/43147 [==============================] - 4s 101us/step - loss: 1.1136 - acc: 0.5381\n",
      "Epoch 22/50\n",
      "43147/43147 [==============================] - 4s 101us/step - loss: 1.1124 - acc: 0.5387\n",
      "Epoch 23/50\n",
      "43147/43147 [==============================] - 4s 101us/step - loss: 1.1107 - acc: 0.5386\n",
      "Epoch 24/50\n",
      "43147/43147 [==============================] - 4s 101us/step - loss: 1.1082 - acc: 0.5416\n",
      "Epoch 25/50\n",
      "43147/43147 [==============================] - 4s 99us/step - loss: 1.1070 - acc: 0.5421\n",
      "Epoch 26/50\n",
      "43147/43147 [==============================] - 4s 102us/step - loss: 1.1056 - acc: 0.5418\n",
      "Epoch 27/50\n",
      "43147/43147 [==============================] - 4s 101us/step - loss: 1.1035 - acc: 0.5411\n",
      "Epoch 28/50\n",
      "43147/43147 [==============================] - 4s 101us/step - loss: 1.1033 - acc: 0.5416\n",
      "Epoch 29/50\n",
      "43147/43147 [==============================] - 4s 103us/step - loss: 1.1018 - acc: 0.5438\n",
      "Epoch 30/50\n",
      "43147/43147 [==============================] - 5s 114us/step - loss: 1.1010 - acc: 0.5435\n",
      "Epoch 31/50\n",
      "43147/43147 [==============================] - 4s 100us/step - loss: 1.0997 - acc: 0.5440\n",
      "Epoch 32/50\n",
      "43147/43147 [==============================] - 4s 101us/step - loss: 1.0980 - acc: 0.5440 1s - \n",
      "Epoch 33/50\n",
      "43147/43147 [==============================] - 4s 101us/step - loss: 1.0971 - acc: 0.5453 0s - loss: 1.0988 - acc:\n",
      "Epoch 34/50\n",
      "43147/43147 [==============================] - 4s 101us/step - loss: 1.0958 - acc: 0.5448\n",
      "Epoch 35/50\n",
      "43147/43147 [==============================] - 4s 100us/step - loss: 1.0955 - acc: 0.5456\n",
      "Epoch 36/50\n",
      "43147/43147 [==============================] - 4s 100us/step - loss: 1.0944 - acc: 0.5440\n",
      "Epoch 37/50\n",
      "43147/43147 [==============================] - 4s 100us/step - loss: 1.0933 - acc: 0.5474\n",
      "Epoch 38/50\n",
      "43147/43147 [==============================] - 4s 82us/step - loss: 1.0924 - acc: 0.5479\n",
      "Epoch 39/50\n",
      "43147/43147 [==============================] - 4s 98us/step - loss: 1.0919 - acc: 0.5462\n",
      "Epoch 40/50\n",
      "43147/43147 [==============================] - 4s 100us/step - loss: 1.0903 - acc: 0.5481\n",
      "Epoch 41/50\n",
      "43147/43147 [==============================] - 4s 100us/step - loss: 1.0904 - acc: 0.5485\n",
      "Epoch 42/50\n",
      "43147/43147 [==============================] - 4s 100us/step - loss: 1.0893 - acc: 0.5481\n",
      "Epoch 43/50\n",
      "43147/43147 [==============================] - 4s 100us/step - loss: 1.0887 - acc: 0.5479\n",
      "Epoch 44/50\n",
      "43147/43147 [==============================] - 4s 101us/step - loss: 1.0883 - acc: 0.5481\n",
      "Epoch 45/50\n",
      "43147/43147 [==============================] - 5s 111us/step - loss: 1.0871 - acc: 0.5490\n",
      "Epoch 46/50\n",
      "43147/43147 [==============================] - 4s 104us/step - loss: 1.0871 - acc: 0.5501\n",
      "Epoch 47/50\n",
      "43147/43147 [==============================] - 4s 100us/step - loss: 1.0859 - acc: 0.5499\n",
      "Epoch 48/50\n",
      "43147/43147 [==============================] - 4s 101us/step - loss: 1.0848 - acc: 0.5496\n",
      "Epoch 49/50\n",
      "43147/43147 [==============================] - 4s 102us/step - loss: 1.0851 - acc: 0.5500 0s - loss: 1.0850 - acc: 0.54\n",
      "Epoch 50/50\n",
      "43147/43147 [==============================] - 4s 102us/step - loss: 1.0843 - acc: 0.5508\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train.values, y_train.values, epochs = 50) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This value seems to be better than the default. This model has the same accuracy as the model with the default parameters except it reached this amount in half the number of epochs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Selection Criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model we found had an accuracy around 57 percent. We were able to find a model that performs much faster wiht 55 percent. I think this model should be used because it is less complex. Also we found that we could change the default learning rate to speed up the learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply cross validation to see how this model does on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    model = build_model(5,18)\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=keras.optimizers.SGD(lr=1e-2), metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "def train_and_evaluate_model(model, train_x, train_y, test_x, test_y ):\n",
    "    print(\"building\")\n",
    "    model.fit(train_x.values, train_y.values, epochs = 20, verbose = 0) # disable printing out a million lines\n",
    "    scores = model.predict_classes(train_x)\n",
    "    print(f'The accuracy score on the training data is {metrics.accuracy_score(scores, train_y)}')\n",
    "    scores = model.predict_classes(test_x)\n",
    "    print(f'The accuracy score on the test data is {metrics.accuracy_score(scores, test_y)}')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to run this with less epochs because my computer freezes up when I do more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Fold 1 / 5\n",
      "building\n",
      "The accuracy score on the training data is 0.5315931280238723\n",
      "The accuracy score on the test data is 0.5274623406720742\n",
      "Running Fold 2 / 5\n",
      "building\n",
      "The accuracy score on the training data is 0.5318828403395428\n",
      "The accuracy score on the test data is 0.5358053302433372\n",
      "Running Fold 3 / 5\n",
      "building\n",
      "The accuracy score on the training data is 0.5340981516889739\n",
      "The accuracy score on the test data is 0.5272916908100591\n",
      "Running Fold 4 / 5\n",
      "building\n",
      "The accuracy score on the training data is 0.532852424821832\n",
      "The accuracy score on the test data is 0.5336655464132576\n",
      "Running Fold 5 / 5\n",
      "building\n",
      "The accuracy score on the training data is 0.5299553855959209\n",
      "The accuracy score on the test data is 0.5274075790937536\n"
     ]
    }
   ],
   "source": [
    "X_train_c = X_train.copy().reset_index()\n",
    "X_train_c.drop('index', axis = 1, inplace = True)\n",
    "y_train_c = y_train.copy().reset_index()\n",
    "y_train_c.drop('index', axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "n_folds = 5\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "for i, (train, test) in enumerate(skf.split(X_train,y_train)):\n",
    "            print (\"Running Fold\", i+1, \"/\", n_folds)\n",
    "            model = None # Clearing the NN.\n",
    "            model = create_model()\n",
    "            train_and_evaluate_model(model, X_train_c.iloc[train], y_train_c.iloc[train], X_train_c.iloc[test], y_train_c.iloc[test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our cross validation shows us we aren't overfitting the data as our scores are around the same. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use this model on our test set. I think all of our models are doing similar but this has the best hyper parameters as 1. it is not overly complex and 2. the learning rate is the highest without negativly impacting the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "43147/43147 [==============================] - 4s 103us/step - loss: 1.0704 - acc: 0.5547\n",
      "Epoch 2/100\n",
      "43147/43147 [==============================] - 6s 130us/step - loss: 1.0699 - acc: 0.5550\n",
      "Epoch 3/100\n",
      "43147/43147 [==============================] - 5s 113us/step - loss: 1.0690 - acc: 0.5557\n",
      "Epoch 4/100\n",
      "43147/43147 [==============================] - 5s 112us/step - loss: 1.0689 - acc: 0.5553\n",
      "Epoch 5/100\n",
      "43147/43147 [==============================] - 4s 104us/step - loss: 1.0679 - acc: 0.5559\n",
      "Epoch 6/100\n",
      "43147/43147 [==============================] - 5s 126us/step - loss: 1.0682 - acc: 0.5555 0s - loss: 1.0696 - acc: \n",
      "Epoch 7/100\n",
      "43147/43147 [==============================] - 6s 135us/step - loss: 1.0676 - acc: 0.5568\n",
      "Epoch 8/100\n",
      "43147/43147 [==============================] - 6s 145us/step - loss: 1.0676 - acc: 0.5567\n",
      "Epoch 9/100\n",
      "43147/43147 [==============================] - 5s 110us/step - loss: 1.0673 - acc: 0.5561\n",
      "Epoch 10/100\n",
      "43147/43147 [==============================] - 5s 107us/step - loss: 1.0669 - acc: 0.5555\n",
      "Epoch 11/100\n",
      "43147/43147 [==============================] - 5s 110us/step - loss: 1.0665 - acc: 0.5563\n",
      "Epoch 12/100\n",
      "43147/43147 [==============================] - 5s 117us/step - loss: 1.0662 - acc: 0.5563\n",
      "Epoch 13/100\n",
      "43147/43147 [==============================] - 7s 154us/step - loss: 1.0657 - acc: 0.5561\n",
      "Epoch 14/100\n",
      "43147/43147 [==============================] - 6s 133us/step - loss: 1.0655 - acc: 0.5571\n",
      "Epoch 15/100\n",
      "43147/43147 [==============================] - 6s 148us/step - loss: 1.0657 - acc: 0.5569\n",
      "Epoch 16/100\n",
      "43147/43147 [==============================] - 6s 132us/step - loss: 1.0656 - acc: 0.5577\n",
      "Epoch 17/100\n",
      "43147/43147 [==============================] - 5s 112us/step - loss: 1.0648 - acc: 0.5575 0s - loss: 1.0641 - acc: 0.5\n",
      "Epoch 18/100\n",
      "43147/43147 [==============================] - 5s 123us/step - loss: 1.0647 - acc: 0.5577\n",
      "Epoch 19/100\n",
      "43147/43147 [==============================] - 5s 127us/step - loss: 1.0648 - acc: 0.5556\n",
      "Epoch 20/100\n",
      "43147/43147 [==============================] - 5s 118us/step - loss: 1.0642 - acc: 0.5579\n",
      "Epoch 21/100\n",
      "43147/43147 [==============================] - 5s 117us/step - loss: 1.0639 - acc: 0.5580\n",
      "Epoch 22/100\n",
      "43147/43147 [==============================] - 5s 114us/step - loss: 1.0646 - acc: 0.5573\n",
      "Epoch 23/100\n",
      "43147/43147 [==============================] - 5s 119us/step - loss: 1.0631 - acc: 0.5584\n",
      "Epoch 24/100\n",
      "43147/43147 [==============================] - 5s 118us/step - loss: 1.0631 - acc: 0.5586\n",
      "Epoch 25/100\n",
      "43147/43147 [==============================] - 5s 122us/step - loss: 1.0628 - acc: 0.5573\n",
      "Epoch 26/100\n",
      "43147/43147 [==============================] - 5s 117us/step - loss: 1.0619 - acc: 0.5602\n",
      "Epoch 27/100\n",
      "43147/43147 [==============================] - 5s 114us/step - loss: 1.0620 - acc: 0.5577\n",
      "Epoch 28/100\n",
      "43147/43147 [==============================] - 6s 131us/step - loss: 1.0622 - acc: 0.5593\n",
      "Epoch 29/100\n",
      "43147/43147 [==============================] - 5s 127us/step - loss: 1.0623 - acc: 0.5581\n",
      "Epoch 30/100\n",
      "43147/43147 [==============================] - 5s 115us/step - loss: 1.0612 - acc: 0.5577\n",
      "Epoch 31/100\n",
      "43147/43147 [==============================] - 5s 113us/step - loss: 1.0616 - acc: 0.5599\n",
      "Epoch 32/100\n",
      "43147/43147 [==============================] - 5s 120us/step - loss: 1.0608 - acc: 0.5577\n",
      "Epoch 33/100\n",
      "43147/43147 [==============================] - 5s 115us/step - loss: 1.0605 - acc: 0.5587\n",
      "Epoch 34/100\n",
      "43147/43147 [==============================] - 5s 124us/step - loss: 1.0603 - acc: 0.5587\n",
      "Epoch 35/100\n",
      "43147/43147 [==============================] - 5s 119us/step - loss: 1.0599 - acc: 0.5581\n",
      "Epoch 36/100\n",
      "43147/43147 [==============================] - 5s 120us/step - loss: 1.0595 - acc: 0.5596\n",
      "Epoch 37/100\n",
      "43147/43147 [==============================] - 5s 117us/step - loss: 1.0596 - acc: 0.5594\n",
      "Epoch 38/100\n",
      "43147/43147 [==============================] - 5s 118us/step - loss: 1.0584 - acc: 0.5599\n",
      "Epoch 39/100\n",
      "43147/43147 [==============================] - 5s 115us/step - loss: 1.0590 - acc: 0.5598\n",
      "Epoch 40/100\n",
      "43147/43147 [==============================] - 5s 124us/step - loss: 1.0585 - acc: 0.5594\n",
      "Epoch 41/100\n",
      "43147/43147 [==============================] - 7s 165us/step - loss: 1.0582 - acc: 0.5599\n",
      "Epoch 42/100\n",
      "43147/43147 [==============================] - 5s 125us/step - loss: 1.0570 - acc: 0.5602\n",
      "Epoch 43/100\n",
      "43147/43147 [==============================] - 5s 121us/step - loss: 1.0578 - acc: 0.5615\n",
      "Epoch 44/100\n",
      "43147/43147 [==============================] - 5s 125us/step - loss: 1.0567 - acc: 0.5618\n",
      "Epoch 45/100\n",
      "43147/43147 [==============================] - 5s 122us/step - loss: 1.0576 - acc: 0.5597\n",
      "Epoch 46/100\n",
      "43147/43147 [==============================] - 5s 122us/step - loss: 1.0565 - acc: 0.5606\n",
      "Epoch 47/100\n",
      "43147/43147 [==============================] - 5s 116us/step - loss: 1.0571 - acc: 0.5597\n",
      "Epoch 48/100\n",
      "43147/43147 [==============================] - 5s 115us/step - loss: 1.0562 - acc: 0.5594\n",
      "Epoch 49/100\n",
      "43147/43147 [==============================] - 6s 130us/step - loss: 1.0557 - acc: 0.5608\n",
      "Epoch 50/100\n",
      "43147/43147 [==============================] - 5s 112us/step - loss: 1.0550 - acc: 0.5624\n",
      "Epoch 51/100\n",
      "43147/43147 [==============================] - 5s 113us/step - loss: 1.0552 - acc: 0.5616\n",
      "Epoch 52/100\n",
      "43147/43147 [==============================] - 6s 139us/step - loss: 1.0552 - acc: 0.5604\n",
      "Epoch 53/100\n",
      "43147/43147 [==============================] - 9s 213us/step - loss: 1.0555 - acc: 0.5609 3s - loss \n",
      "Epoch 54/100\n",
      "43147/43147 [==============================] - 5s 124us/step - loss: 1.0553 - acc: 0.5623 0s - loss: 1.0551 - acc: 0.5\n",
      "Epoch 55/100\n",
      "43147/43147 [==============================] - 5s 126us/step - loss: 1.0539 - acc: 0.5630\n",
      "Epoch 56/100\n",
      "43147/43147 [==============================] - 5s 112us/step - loss: 1.0549 - acc: 0.5620\n",
      "Epoch 57/100\n",
      "43147/43147 [==============================] - 5s 119us/step - loss: 1.0538 - acc: 0.5615\n",
      "Epoch 58/100\n",
      "43147/43147 [==============================] - 5s 112us/step - loss: 1.0549 - acc: 0.5613\n",
      "Epoch 59/100\n",
      "43147/43147 [==============================] - 5s 112us/step - loss: 1.0539 - acc: 0.5599\n",
      "Epoch 60/100\n",
      "43147/43147 [==============================] - 5s 127us/step - loss: 1.0540 - acc: 0.5627\n",
      "Epoch 61/100\n",
      "43147/43147 [==============================] - 6s 142us/step - loss: 1.0529 - acc: 0.5632\n",
      "Epoch 62/100\n",
      "43147/43147 [==============================] - 5s 113us/step - loss: 1.0534 - acc: 0.5613\n",
      "Epoch 63/100\n",
      "43147/43147 [==============================] - 5s 124us/step - loss: 1.0534 - acc: 0.5603\n",
      "Epoch 64/100\n",
      "43147/43147 [==============================] - 5s 123us/step - loss: 1.0527 - acc: 0.5628\n",
      "Epoch 65/100\n",
      "43147/43147 [==============================] - 6s 133us/step - loss: 1.0533 - acc: 0.5619 0s - loss: 1.\n",
      "Epoch 66/100\n",
      "43147/43147 [==============================] - 5s 120us/step - loss: 1.0523 - acc: 0.5614\n",
      "Epoch 67/100\n",
      "43147/43147 [==============================] - 5s 113us/step - loss: 1.0520 - acc: 0.5633\n",
      "Epoch 68/100\n",
      "43147/43147 [==============================] - 5s 126us/step - loss: 1.0515 - acc: 0.5633\n",
      "Epoch 69/100\n",
      "43147/43147 [==============================] - 6s 138us/step - loss: 1.0518 - acc: 0.5627\n",
      "Epoch 70/100\n",
      "43147/43147 [==============================] - 5s 118us/step - loss: 1.0515 - acc: 0.5634\n",
      "Epoch 71/100\n",
      "43147/43147 [==============================] - 5s 117us/step - loss: 1.0519 - acc: 0.5622\n",
      "Epoch 72/100\n",
      "43147/43147 [==============================] - 5s 118us/step - loss: 1.0515 - acc: 0.5622\n",
      "Epoch 73/100\n",
      "43147/43147 [==============================] - 5s 115us/step - loss: 1.0512 - acc: 0.5627\n",
      "Epoch 74/100\n",
      "43147/43147 [==============================] - 5s 120us/step - loss: 1.0516 - acc: 0.5618\n",
      "Epoch 75/100\n",
      "43147/43147 [==============================] - 5s 117us/step - loss: 1.0505 - acc: 0.5631 1s - los\n",
      "Epoch 76/100\n",
      "43147/43147 [==============================] - 5s 122us/step - loss: 1.0504 - acc: 0.5652\n",
      "Epoch 77/100\n",
      "43147/43147 [==============================] - 5s 115us/step - loss: 1.0501 - acc: 0.5630\n",
      "Epoch 78/100\n",
      "43147/43147 [==============================] - 5s 125us/step - loss: 1.0503 - acc: 0.5624\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43147/43147 [==============================] - 5s 109us/step - loss: 1.0505 - acc: 0.5638\n",
      "Epoch 80/100\n",
      "43147/43147 [==============================] - 5s 112us/step - loss: 1.0496 - acc: 0.5624\n",
      "Epoch 81/100\n",
      "43147/43147 [==============================] - 5s 115us/step - loss: 1.0502 - acc: 0.5621\n",
      "Epoch 82/100\n",
      "43147/43147 [==============================] - 5s 122us/step - loss: 1.0491 - acc: 0.5626\n",
      "Epoch 83/100\n",
      "43147/43147 [==============================] - 6s 132us/step - loss: 1.0493 - acc: 0.5628\n",
      "Epoch 84/100\n",
      "43147/43147 [==============================] - 5s 118us/step - loss: 1.0493 - acc: 0.5628\n",
      "Epoch 85/100\n",
      "43147/43147 [==============================] - 5s 112us/step - loss: 1.0483 - acc: 0.5632\n",
      "Epoch 86/100\n",
      "43147/43147 [==============================] - 5s 110us/step - loss: 1.0483 - acc: 0.5653\n",
      "Epoch 87/100\n",
      "43147/43147 [==============================] - 5s 109us/step - loss: 1.0489 - acc: 0.5640\n",
      "Epoch 88/100\n",
      "43147/43147 [==============================] - 5s 111us/step - loss: 1.0488 - acc: 0.5631\n",
      "Epoch 89/100\n",
      "43147/43147 [==============================] - 5s 111us/step - loss: 1.0482 - acc: 0.5638\n",
      "Epoch 90/100\n",
      "43147/43147 [==============================] - 5s 110us/step - loss: 1.0481 - acc: 0.5643\n",
      "Epoch 91/100\n",
      "43147/43147 [==============================] - 5s 124us/step - loss: 1.0482 - acc: 0.5643\n",
      "Epoch 92/100\n",
      "43147/43147 [==============================] - 5s 114us/step - loss: 1.0481 - acc: 0.5655\n",
      "Epoch 93/100\n",
      "43147/43147 [==============================] - 5s 110us/step - loss: 1.0477 - acc: 0.5641\n",
      "Epoch 94/100\n",
      "43147/43147 [==============================] - 5s 110us/step - loss: 1.0459 - acc: 0.5668\n",
      "Epoch 95/100\n",
      "43147/43147 [==============================] - 5s 110us/step - loss: 1.0465 - acc: 0.5649\n",
      "Epoch 96/100\n",
      "43147/43147 [==============================] - 5s 112us/step - loss: 1.0469 - acc: 0.5652\n",
      "Epoch 97/100\n",
      "43147/43147 [==============================] - 5s 110us/step - loss: 1.0469 - acc: 0.5632\n",
      "Epoch 98/100\n",
      "43147/43147 [==============================] - 5s 111us/step - loss: 1.0467 - acc: 0.5643\n",
      "Epoch 99/100\n",
      "43147/43147 [==============================] - 5s 112us/step - loss: 1.0460 - acc: 0.5657\n",
      "Epoch 100/100\n",
      "43147/43147 [==============================] - 5s 110us/step - loss: 1.0463 - acc: 0.5650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1abee1d39b0>"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train.values,y_train.values, epochs = 100, verbose = 1) # 100 we saw is high enough that it stops improving so much after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score on the test data is 0.547232780198387\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.82      0.68      4343\n",
      "           2       0.54      0.45      0.49      2740\n",
      "           3       0.37      0.26      0.31      2358\n",
      "           4       0.55      0.33      0.41       994\n",
      "           5       0.78      0.49      0.60       352\n",
      "\n",
      "    accuracy                           0.55     10787\n",
      "   macro avg       0.57      0.47      0.50     10787\n",
      "weighted avg       0.53      0.55      0.53     10787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = model.predict_classes(X_test.values)\n",
    "print(f'The accuracy score on the test data is {metrics.accuracy_score(scores, y_test)}')\n",
    "print(metrics.classification_report(y_test,scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6059\n",
       "2    2259\n",
       "3    1656\n",
       "4     593\n",
       "5     220\n",
       "dtype: int64"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(scores).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4343\n",
       "2    2740\n",
       "3    2358\n",
       "4     994\n",
       "5     352\n",
       "Name: cut, dtype: int64"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, our model is predicting too many ones but it is still predicting values in other categories. Each category has a precision above .5 except for category 3 which has a precision of .37 meaning it isn't able to predict it so well. This makes sense though as predicting the exact value of a class in the middle could be harder. We see that our model is correct most of the time it predicts a category 5 with .78. Remember 5 is the worst variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, I don't think this model should be used. We saw in the assignment last week models like XGBoost and Random Forest outperform this model and is a bit simpler and less of a black box."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We saw from our EDA that many of our features were correlated, although the correlations were weaker with the cut variable.\n",
    "2. Neural Nets did not suffer as much from overfitting as the random forest from last week yet overall performed a bit worse. \n",
    "3. We need around 100 epochs to achieve the greatest performance. The other parameters didn't seem to effect the model too much. If we had more compute power we could try more than 100 as we saw the performance was still increasing after 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
