{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benny Cohen\n",
    "\n",
    "DAV 6150\n",
    "\n",
    "Module 5 Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we are interested in creating functions to help evaluate machine learning models. \n",
    "\n",
    "We will create the functions then test them on a dataset containing the results of a model. \n",
    "\n",
    "I am not particularly interested in creating optimal functions since scikit learn is already more optimized. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will import our test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>glucose</th>\n",
       "      <th>diastolic</th>\n",
       "      <th>skinfold</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "      <th>scored.class</th>\n",
       "      <th>scored.probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>124</td>\n",
       "      <td>70</td>\n",
       "      <td>33</td>\n",
       "      <td>215</td>\n",
       "      <td>25.5</td>\n",
       "      <td>0.161</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.328452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>76</td>\n",
       "      <td>27</td>\n",
       "      <td>200</td>\n",
       "      <td>35.9</td>\n",
       "      <td>0.483</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.273190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>62</td>\n",
       "      <td>13</td>\n",
       "      <td>48</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.678</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.109660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>64</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>29.2</td>\n",
       "      <td>0.192</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.055998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>83</td>\n",
       "      <td>86</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>29.3</td>\n",
       "      <td>0.317</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.100491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnant  glucose  diastolic  skinfold  insulin   bmi  pedigree  age  \\\n",
       "0         7      124         70        33      215  25.5     0.161   37   \n",
       "1         2      122         76        27      200  35.9     0.483   26   \n",
       "2         3      107         62        13       48  22.9     0.678   23   \n",
       "3         1       91         64        24        0  29.2     0.192   21   \n",
       "4         4       83         86        19        0  29.3     0.317   34   \n",
       "\n",
       "   class  scored.class  scored.probability  \n",
       "0      0             0            0.328452  \n",
       "1      0             0            0.273190  \n",
       "2      1             0            0.109660  \n",
       "3      0             0            0.055998  \n",
       "4      0             0            0.100491  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseurl = 'https://raw.githubusercontent.com'\n",
    "username = 'cohenb51'\n",
    "branch = 'develop'\n",
    "repo = 'Katz_School'\n",
    "filePath = 'DAV6150/m5/M5_Data.csv'\n",
    "\n",
    "df = pd.read_csv(f'{baseurl}/{username}/{repo}/{branch}/{filePath}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['class', 'scored.class', 'scored.probability']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>scored.class</th>\n",
       "      <th>scored.probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.328452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.273190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.109660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.055998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.100491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  scored.class  scored.probability\n",
       "0      0             0            0.328452\n",
       "1      0             0            0.273190\n",
       "2      1             0            0.109660\n",
       "3      0             0            0.055998\n",
       "4      0             0            0.100491"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a binary classifier. The class column can either be a 0 or a 1. The actual context doesn't per say matter for us since we are only interested in evaluating how our metric functions do. \n",
    "\n",
    "The class represents the true value. The scored.class represents the model's prediction. The scored.probability represents the probability that the class is a 1 with the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 181 rows to work with. We will see in the next section the breakdown of predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How pd.crosstab works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using pandas's crosstab function to give us a frequency count. We can use this as our confusion matrix to calculate our statistics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>scored.class</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "scored.class    0   1\n",
       "class                \n",
       "0             119   5\n",
       "1              30  27"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossTab = pd.crosstab(df['class'],df['scored.class'])\n",
    "crossTab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us the 119 were correctly predicted negative, 27 correctly predicted postive, 5 incorrectly predicted positive, and 30 incorrectly predicted negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also check this with a group by. This really is the same thing just with a different index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>scored.probability</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th>scored.class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    scored.probability\n",
       "class scored.class                    \n",
       "0     0                            119\n",
       "      1                              5\n",
       "1     0                             30\n",
       "      1                             27"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check \n",
    "df.groupby(['class', 'scored.class']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the same results here. I think this is slightly easier to look at since we could read accross."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since pd.crosstab is a frequency count it would not preform correctly where there are no entries for a given value. (ex. all were predicted negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>scored.class</th>\n",
       "      <th>scored.probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.27319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  scored.class  scored.probability\n",
       "1      0             0             0.27319"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDf = df.iloc[1:2]\n",
    "testDf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we have 1 negative prediction..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>scored.class</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "scored.class  0\n",
       "class          \n",
       "0             1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossTab = pd.crosstab(testDf['class'],testDf['scored.class'])\n",
    "crossTab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are going to index the pd.crosstab to create our statistics we need a way to guarantee that the crosstab will be a 2x2 matrix. (since we are doing a binary classifier). One way we can do this is by just arbitrarily adding 1 of each type of prediction. We will do this in our code below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper class for readability purposes.\n",
    "class ConfusionMatrix():\n",
    "    def __init__(self,actual, predicted):\n",
    "        self.validate(actual,predicted)\n",
    "        actual_c = list(actual)      \n",
    "        predicted_c = list(predicted)\n",
    "        \n",
    "        # Append fake values to assure us a 2x2 matrix.\n",
    "        actual_c.append(0)\n",
    "        predicted_c.append(0)\n",
    "        \n",
    "        actual_c.append(1)\n",
    "        predicted_c.append(0)\n",
    "        \n",
    "        actual_c.append(0)\n",
    "        predicted_c.append(1)\n",
    "        \n",
    "        actual_c.append(1)\n",
    "        predicted_c.append(1)\n",
    "        \n",
    "        dc = pd.Series(actual_c)\n",
    "        dc2 = pd.Series(predicted_c)\n",
    "     \n",
    "        self.crossTab = pd.crosstab(dc,dc2)\n",
    "        if self.crossTab.shape != (2,2):\n",
    "            raise Exception(\"This class only works for binary classifiers.\")\n",
    "        self.Size = len(actual)\n",
    "        \n",
    "    def validate(self, actual, predicted):\n",
    "        if len(actual) != len(predicted):\n",
    "            raise Exception(\"The length of the predictions do not match the length of the actual values\")\n",
    "            \n",
    "    def TruePositives(self):\n",
    "        return self.crossTab[1][1] -1\n",
    "    \n",
    "    def TrueNegatives(self):\n",
    "        return self.crossTab[0][0] -1\n",
    "    \n",
    "    def FalsePositives(self):\n",
    "        return self.crossTab[1][0] -1\n",
    "    \n",
    "    def FalseNegatives(self):\n",
    "        return self.crossTab[0][1] -1\n",
    "    \n",
    "    def ConfusionMatrix(self):\n",
    "        clone = self.crossTab.copy()\n",
    "        clone[0][0] = self.crossTab[0][0] -1\n",
    "        clone[0][1] = self.crossTab[0][1] - 1\n",
    "        clone[1][0] = self.crossTab[1][0] -1\n",
    "        clone[1][1] = self.crossTab[1][1] -1\n",
    "        return clone\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm not really sure how to make the self.crosstab a private variable because really it shouldn't be accessed directly. It will clearly give the wrong confusion matrix as I am increasing the value of each row and column by one. I also don't want people to be able to edit the value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy\n",
    "\n",
    "This gives us ratio of correctly predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetAccuracy(actual, predicted):\n",
    "    confusionMatrix = ConfusionMatrix(actual, predicted)\n",
    "    return (confusionMatrix.TruePositives() + confusionMatrix.TrueNegatives()) / confusionMatrix.Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision\n",
    "\n",
    "This gives us the ratio of correct positive predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetPrecision(actual, predicted):\n",
    "    confusionMatrix = ConfusionMatrix(actual, predicted)\n",
    "    return confusionMatrix.TruePositives() /  (confusionMatrix.TruePositives() + confusionMatrix.FalsePositives())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sensitivity \n",
    "\n",
    "This gives us the ratio of actual positives that were predicted correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetSensitivity(actual, predicted):\n",
    "    confusionMatrix = ConfusionMatrix(actual, predicted)\n",
    "    return confusionMatrix.TruePositives()/ (confusionMatrix.TruePositives() + confusionMatrix.FalseNegatives())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specifity\n",
    "\n",
    "This gives us the ratio of actual negatives which were predicted correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetSpecifity(actual, predicted):\n",
    "    confusionMatrix = ConfusionMatrix(actual, predicted)\n",
    "    return confusionMatrix.TrueNegatives() / (confusionMatrix.TrueNegatives() + confusionMatrix.FalsePositives())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 Score\n",
    "\n",
    "This is a function of recall (sensitivity) and precision. The single number it outputs is a useful metric to compare both recall and precision between models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetF1Score(actual, predicted):\n",
    "    precision = GetPrecision(actual,predicted) # I guess we could optimize this to use 1 confusion matrix. \n",
    "    recall = GetSensitivity(actual,predicted)\n",
    "    return 2 * (precision * recall)/(precision+recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roc and Auc Curve\n",
    "The roc curve plots 1-specifity on the x axis and the sensitivity on the y axis. Naturally, The more area under the graph the better the model. A random graph would be along the line x = y since half the guesses would be correct and half wrong. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot(x,y):\n",
    "    plt.plot(x,y)\n",
    "def GetRegularCutoffs():\n",
    "    return np.arange(0,1, .005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cutoffs is an array of what points to evaluate at. The more elements, the longer it will take to complete. \n",
    "# I do not do any validations on this since it is just for me to use. It is slow because the Get Specifity and Sensitivity are really slow.\n",
    "#There probably is a way to cache results. \n",
    "\n",
    "#Note: Cutoffs must be ordered from low to high for auc calculation to work properly. \n",
    "def GetRocPlot(actual, predicted, probs, cutoffs = None):\n",
    "    if cutoffs == None:\n",
    "        cutoffs = GetRegularCutoffs()\n",
    "    y = []\n",
    "    x = []\n",
    "    for cutoff in cutoffs:\n",
    "        tPred = probs.map(lambda x: 0 if x < cutoff else 1)\n",
    "        x.append(1 - GetSpecifity(actual, tPred))\n",
    "        y.append(GetSensitivity(actual, tPred))\n",
    "    Plot(x, y)\n",
    "    return (x, y, GetAuc(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auc gives the area under the roc curve. The closer to 1 the better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetAuc(x,y):\n",
    "    sum = 0\n",
    "    xStart = x[1]\n",
    "    for i in range(1, len(x)): \n",
    "        dy = y[i-1] - y[i] \n",
    "        if(dy >0):\n",
    "            dx = (xStart - x[i])\n",
    "            dy = y[i -1]\n",
    "            if y[i] == 0:\n",
    "                triangle = (dx * dy)/2\n",
    "                sum = sum + triangle\n",
    "                break\n",
    "            sum = sum + dx * dy\n",
    "            xStart = x[i]\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we are just going to get the outputs of using the functions on our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8066298342541437"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GetAccuracy(df['class'],df['scored.class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84375"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GetPrecision(df['class'],df['scored.class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47368421052631576"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GetSensitivity(df['class'],df['scored.class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9596774193548387"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GetSpecifity(df['class'],df['scored.class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6067415730337079"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GetF1Score(df['class'],df['scored.class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compare with scikit learn functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: scikit-learn: 0.8066298342541437 Mine: 0.8066298342541437\n",
      "Precision: scikit-learn: 0.84375 Mine: 0.84375\n",
      "Recall: scikit-learn: 0.47368421052631576 Mine: 0.47368421052631576\n",
      "f1Score: scikit-learn: 0.6067415730337079 Mine: 0.6067415730337079\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "print(f\"Accuracy: scikit-learn: {metrics.accuracy_score(df['class'],df['scored.class'])} Mine: {GetAccuracy(df['class'],df['scored.class'])}\")\n",
    "print(f\"Precision: scikit-learn: {metrics.precision_score(df['class'],df['scored.class'])} Mine: {GetPrecision(df['class'],df['scored.class'])}\")\n",
    "print(f\"Recall: scikit-learn: {metrics.recall_score(df['class'],df['scored.class'])} Mine: {GetSensitivity(df['class'],df['scored.class'])}\")\n",
    "print(f\"f1Score: scikit-learn: {metrics.f1_score(df['class'],df['scored.class'])} Mine: {GetF1Score(df['class'],df['scored.class'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[119,   5],\n",
       "       [ 30,  27]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(df['class'],df['scored.class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    0   1\n",
       "row_0         \n",
       "0      119   5\n",
       "1       30  27"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConfusionMatrix(df['class'],df['scored.class']).ConfusionMatrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our confusion matrix is functionally the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.80      0.96      0.87       124\\n           1       0.84      0.47      0.61        57\\n\\n    accuracy                           0.81       181\\n   macro avg       0.82      0.72      0.74       181\\nweighted avg       0.81      0.81      0.79       181\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.classification_report(df['class'],df['scored.class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the same scores as above just rounded. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compare our roc curve. First ours..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8525042444821731"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_,_, auc = GetRocPlot(df['class'],df['scored.class'], df['scored.probability'])\n",
    "auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now theirs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(df['class'],df['scored.probability'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x150eb691b38>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAD/ZJREFUeJzt3WGI5Hd9x/H3x0tTaZuY0jvhzF28SC/gGorKEhWhphhLDHj3RO2lSGsJntrGPlAKKZYo8YlVWlE41MNKVNAk+sAscpJSG7GIl96KMZoLKdeoySahWW2aPBCNod8+mDk72Zvb+e/u7M7Mb94vOJj/zO9mvr+b3U9++c5v/v9UFZKktjxv0gVIksbPcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ16IJJvfDu3bvrwIEDk3p5SZpJ3/3ud39aVXtGjZtYuB84cIDl5eVJvbwkzaQkP+kyzraMJDXIcJekBhnuktQgw12SGmS4S1KDRoZ7ks8meSLJD8/zeJJ8IsmZJPcleeX4y5QkbUSXlfutwLXrPP5G4GD/z1Hgk1svS5K0FSP3uVfVt5IcWGfIYeDz1bte38kklyTZW1WPj6lGSVPii/c8zJ33PjrpMmbewosu5gNvetm2vsY4eu6XAo8MHK/07ztHkqNJlpMsr66ujuGlJe2kO+99lNOPPz3pMtTBOL6hmiH3Db3qdlUdB44DLC4uemVuaQYt7L2Y29/5mkmXoRHGsXJfAfYPHO8DHhvD80qSNmkcK/cl4MYktwGvAp6y3y5Nh3H3yE8//jQLey8e2/Np+4wM9yRfAq4GdidZAT4A/AZAVX0KOAFcB5wBfg78xXYVK2ljzvbIxxXIC3sv5vDLh36kpinTZbfM9SMeL+CvxlaRpLGyRz6fJnbKX0njsV7rxTbK/PL0A9KMW297om2U+eXKXWqArRet5cpdkhrkyl1itr9Wb19dw7hyl5jtr9XbV9cwrtylPvvWaonhrrl2th1ja0OtsS2juTYY7LY21BJX7pp7tmPUIlfuktQgV+6aG8O2O9prV6tcuWtuDNvuaK9drXLlrrlif13zwnBX0wZbMbZgNE9sy6hpg60YWzCaJ67c1TxbMZpHrtwlqUGu3NUkTyugeefKXU3ytAKad67c1Sx77ZpnhrumzjgunGE7RvPOtoymzjgunGE7RvPOlbumki0VaWsMd+2Yru0WWyrS1tmW0Y7p2m6xpSJtnSt37SjbLdLOcOUuSQ1y5a5t4YUxpMly5a5t4YUxpMnqtHJPci3wcWAX8Jmq+vCaxy8DPgdc0h9zU1WdGHOtmjH216XJGRnuSXYBx4A3ACvAqSRLVXV6YNjfAXdU1SeTLAAngAPbUK+mxKhtjbZgpMnq0pa5CjhTVQ9V1TPAbcDhNWMKOPub/ALgsfGVqGk0alujLRhpsrq0ZS4FHhk4XgFetWbMB4F/TvIe4LeBa8ZSnaaabRdpenVZuWfIfbXm+Hrg1qraB1wHfCHJOc+d5GiS5STLq6urG69WktRJl3BfAfYPHO/j3LbLDcAdAFX1HeD5wO61T1RVx6tqsaoW9+zZs7mKJUkjdQn3U8DBJJcnuRA4AiytGfMw8HqAJC+lF+4uzSVpQkaGe1U9C9wI3AU8QG9XzP1JbklyqD/sfcA7knwf+BLw9qpa27qRJO2QTvvc+3vWT6y57+aB26eB1463NE3aetsd3eooTTe/oarzWm+7o1sdpenmuWW0Lrc7SrPJlbskNciV+4wYx0WjN8q+ujS7XLnPiHFcNHqj7KtLs8uV+wyx/y2pK1fuktQgw12SGmS4S1KDDHdJapAfqE6xwe2PbkuUtBGu3KfY4PZHtyVK2ghX7lPO7Y+SNsNwH4Pt+vaorRhJm2VbZgy269ujtmIkbZYr9zGxfSJpmrhyl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXILzFtwdnTDniaAEnTxpX7FgwGu6cJkDRNXLlvkacdkDSNXLlLUoMMd0lqkOEuSQ0y3CWpQZ0+UE1yLfBxYBfwmar68JAxbwU+CBTw/ar60zHWOXHDrrbkFkhJ02pkuCfZBRwD3gCsAKeSLFXV6YExB4G/BV5bVU8meeF2FTwpw/azuwVS0rTqsnK/CjhTVQ8BJLkNOAycHhjzDuBYVT0JUFVPjLvQaeC2R0mzokvP/VLgkYHjlf59g64Arkjy7SQn+22ccyQ5mmQ5yfLq6urmKpYkjdQl3DPkvlpzfAFwELgauB74TJJLzvlLVcerarGqFvfs2bPRWiVJHXUJ9xVg/8DxPuCxIWPurKpfVdWPgAfphb0kaQK69NxPAQeTXA48ChwB1u6E+Sq9FfutSXbTa9M8NM5Cd5I7YyTNupEr96p6FrgRuAt4ALijqu5PckuSQ/1hdwE/S3IauBv4m6r62XYVvd3O7owZ5M4YSbOk0z73qjoBnFhz380Dtwt4b/9PE9wZI2mW+Q1VSWqQ4S5JDTLcJalBhrskNcgrMfUNbn9026OkWefKvW9w+6PbHiXNOlfuA9z+KKkVrtwlqUFzv3I/22u3zy6pJXO/ch8Mdvvsklox9yt3sNcuqT1zv3KXpBYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBze1zH3Zx6/X4zVRJLWpu5T7s4tbr8ZupklrU3Mod/MapJDW3cpckGe6S1CTDXZIaZLhLUoOa+EDVi1tL0nM1sXL34taS9FxNrNzB7Y+SNKiJlbsk6bkMd0lqUKdwT3JtkgeTnEly0zrj3pykkiyOr0RJ0kaNDPcku4BjwBuBBeD6JAtDxl0E/DVwz7iLlCRtTJeV+1XAmap6qKqeAW4DDg8Z9yHgI8AvxlifJGkTuoT7pcAjA8cr/ft+LckrgP1V9bUx1iZJ2qQu4Z4h99WvH0yeB3wMeN/IJ0qOJllOsry6utq9SknShnQJ9xVg/8DxPuCxgeOLgCuBbyb5MfBqYGnYh6pVdbyqFqtqcc+ePZuvWpK0ri7hfgo4mOTyJBcCR4Clsw9W1VNVtbuqDlTVAeAkcKiqlrelYknSSCPDvaqeBW4E7gIeAO6oqvuT3JLk0HYXKEnauE6nH6iqE8CJNffdfJ6xV2+9LEnSVsz0uWXOng3SM0FK0nPN9OkHBoPdM0FK0v+b6ZU7eDZISRpmplfukqThDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGdwj3JtUkeTHImyU1DHn9vktNJ7kvyjSQvHn+pkqSuRoZ7kl3AMeCNwAJwfZKFNcO+ByxW1R8AXwE+Mu5CJUnddVm5XwWcqaqHquoZ4Dbg8OCAqrq7qn7ePzwJ7BtvmZKkjegS7pcCjwwcr/TvO58bgK8PeyDJ0STLSZZXV1e7VylJ2pAu4Z4h99XQgcnbgEXgo8Mer6rjVbVYVYt79uzpXqUkaUMu6DBmBdg/cLwPeGztoCTXAO8HXldVvxxPeZKkzeiycj8FHExyeZILgSPA0uCAJK8APg0cqqonxl+mJGkjRoZ7VT0L3AjcBTwA3FFV9ye5Jcmh/rCPAr8DfDnJvUmWzvN0kqQd0KUtQ1WdAE6sue/mgdvXjLkuSdIW+A1VSWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGXTDpAjbqi/c8zJ33PgrA6cefZmHvxROuSJKmT6eVe5JrkzyY5EySm4Y8/ptJbu8/fk+SA+Mu9Kw7732U048/DcDC3os5/PJLt+ulJGlmjVy5J9kFHAPeAKwAp5IsVdXpgWE3AE9W1e8nOQL8PfAn21Ew9EL99ne+ZrueXpJmXpeV+1XAmap6qKqeAW4DDq8Zcxj4XP/2V4DXJ8n4ypQkbUSXcL8UeGTgeKV/39AxVfUs8BTwe+MoUJK0cV0+UB22Aq9NjCHJUeAowGWXXdbhpc+18CI/QJWkUbqE+wqwf+B4H/DYecasJLkAeAHw32ufqKqOA8cBFhcXzwn/Lj7wppdt5q9J0lzp0pY5BRxMcnmSC4EjwNKaMUvAn/dvvxn416raVHhLkrZu5Mq9qp5NciNwF7AL+GxV3Z/kFmC5qpaAfwK+kOQMvRX7ke0sWpK0vk5fYqqqE8CJNffdPHD7F8BbxluaJGmzPP2AJDXIcJekBhnuktQgw12SGmS4S1KDMqnt6ElWgZ9s8q/vBn46xnJmgXOeD855Pmxlzi+uqj2jBk0s3LciyXJVLU66jp3knOeDc54POzFn2zKS1CDDXZIaNKvhfnzSBUyAc54Pznk+bPucZ7LnLkla36yu3CVJ65jqcJ+mC3PvlA5zfm+S00nuS/KNJC+eRJ3jNGrOA+PenKSSzPzOii5zTvLW/nt9f5Iv7nSN49bhZ/uyJHcn+V7/5/u6SdQ5Lkk+m+SJJD88z+NJ8on+v8d9SV451gKqair/0Du98H8CLwEuBL4PLKwZ85fAp/q3jwC3T7ruHZjzHwG/1b/97nmYc3/cRcC3gJPA4qTr3oH3+SDwPeB3+8cvnHTdOzDn48C7+7cXgB9Puu4tzvkPgVcCPzzP49cBX6d3JbtXA/eM8/WneeU+jxfmHjnnqrq7qn7ePzxJ78pYs6zL+wzwIeAjwC92srht0mXO7wCOVdWTAFX1xA7XOG5d5lzA2etovoBzr/g2U6rqWwy5It2Aw8Dnq+ckcEmSveN6/WkO93m8MHeXOQ+6gd5/+WfZyDkneQWwv6q+tpOFbaMu7/MVwBVJvp3kZJJrd6y67dFlzh8E3pZkhd71I96zM6VNzEZ/3zek08U6JmRsF+aeIZ3nk+RtwCLwum2taPutO+ckzwM+Brx9pwraAV3e5wvotWaupvd/Z/+W5Mqq+p9trm27dJnz9cCtVfUPSV5D7+puV1bV/25/eROxrfk1zSv3jVyYm/UuzD1DusyZJNcA7wcOVdUvd6i27TJqzhcBVwLfTPJjer3JpRn/ULXrz/adVfWrqvoR8CC9sJ9VXeZ8A3AHQFV9B3g+vXOwtKrT7/tmTXO4z+OFuUfOud+i+DS9YJ/1PiyMmHNVPVVVu6vqQFUdoPc5w6GqWp5MuWPR5Wf7q/Q+PCfJbnptmod2tMrx6jLnh4HXAyR5Kb1wX93RKnfWEvBn/V0zrwaeqqrHx/bsk/5EecSnzdcB/0HvU/b39++7hd4vN/Te/C8DZ4B/B14y6Zp3YM7/AvwXcG//z9Kka97uOa8Z+01mfLdMx/c5wD8Cp4EfAEcmXfMOzHkB+Da9nTT3An886Zq3ON8vAY8Dv6K3Sr8BeBfwroH3+Fj/3+MH4/659huqktSgaW7LSJI2yXCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalB/wfOjW3QCohesQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fpr,tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These graphs look very similar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: scikit-learn: 0.8503112620260327 Mine: 0.8525042444821731\n"
     ]
    }
   ],
   "source": [
    "print(f\"AUC: scikit-learn: {metrics.auc(fpr, tpr)} Mine: {auc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our auc's are about the same (to the hundreths place at least). Scikit Learn is much faster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn only evaluated the graph at 51 points. I'm not really sure where that 51 came from. My function lets you provide where to evaluate the function by providing a list but by default I call the below function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GetRegularCutoffs().shape[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is how many points I evaluate the function at. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
